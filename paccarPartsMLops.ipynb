{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a9017ca1-561f-4f73-abb4-9150e397dc96",
   "metadata": {},
   "source": [
    "# Description "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3393a2e1-02aa-414c-9c80-3936b5badf48",
   "metadata": {},
   "source": [
    "__Program__ : paccarPartsMLOps  \n",
    "__Description__: predicting the PACCAR Parts regional hits  \n",
    "__Team__: Cascade Consulting  \n",
    "__Author__: Saran Pavuluri -- _with assistance from Kelly, Ben, Mohan, Jeremy, Joy and Dohoon_  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "426b04cc-d125-4bc9-9469-259792af1beb",
   "metadata": {},
   "source": [
    "#### import required libraries:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6fb804d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.tree import DecisionTreeClassifier, plot_tree\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score,confusion_matrix\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fc7ca21-4ec8-4ad7-8c86-566037092b61",
   "metadata": {},
   "source": [
    "#### Set the max columns and rows to max, to enable viewing of data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "09425c11-2285-4317-abfe-d772e8d1af2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_rows', None)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f213c57-e794-48cb-abdb-e33c1750fd68",
   "metadata": {},
   "source": [
    "#### read the data file into a pandas dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "56ea7068-1e79-4153-b7e2-25c3ef5580f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"training_data_0101_0514.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8134dbe-172d-470b-9bd0-1baa95e26423",
   "metadata": {},
   "source": [
    "#### Checking if there is an inbalance in the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "04ac22dd-624a-46b9-84f5-2530c4d532d8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "rhit_label\n",
       "0    0.692619\n",
       "1    0.307381\n",
       "Name: count, dtype: float64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.value_counts('rhit_label')/len(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27c570c3-5899-48f9-9e56-f1e0a76dd657",
   "metadata": {},
   "source": [
    "No imbalance exists in the data distribution, let us see how many columns have NA's and handle them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4f0e8233",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ID                              0\n",
       "suggestion_dt                   0\n",
       "expid                           0\n",
       "expid_desc                      0\n",
       "item_id                         0\n",
       "pdc                             0\n",
       "vndr_concat                     0\n",
       "desk                            0\n",
       "velocity                        0\n",
       "part_cost                      14\n",
       "spq                             0\n",
       "ord_min                         0\n",
       "ord_mult                        0\n",
       "ord_dollar_min                  0\n",
       "lead_time                       0\n",
       "on_hand                         0\n",
       "on_order                        0\n",
       "ss_units_left_pct             345\n",
       "max_oh_left_pct                62\n",
       "days_on_hand                    0\n",
       "oh_oo_sug_dos                   0\n",
       "oo_dos                          0\n",
       "doh_less_ss                     0\n",
       "doh_to_ltm                      0\n",
       "oo_it_portion                   0\n",
       "oh_5d_change                30506\n",
       "min_on_hand_change_5d       19690\n",
       "days_below_ss                   0\n",
       "fcst_3m                         0\n",
       "fcst_daily                      0\n",
       "supplier_past_due_pct        4990\n",
       "ots_pct                      9321\n",
       "early_ratio                  8669\n",
       "on_time_ratio                8669\n",
       "no_ship_ratio                8669\n",
       "dmd_rolling_90d              9724\n",
       "dmd_fcst_portion             9724\n",
       "orders_12m                     14\n",
       "dmd_wkly_95pct               4913\n",
       "dmd_wkly_dos                 4921\n",
       "mdi_stockouts               29241\n",
       "network_avail               29241\n",
       "ltm_median                  11003\n",
       "ltm_75pct                   11003\n",
       "ltm_90pct                   11003\n",
       "ltm_90pct_difference_wks    11003\n",
       "rhit_within_2wks                0\n",
       "rhit_label                      0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5df1595b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>item_id</th>\n",
       "      <th>part_cost</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>45055</th>\n",
       "      <td>28243-6CN2</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68816</th>\n",
       "      <td>I-BC-L9780-21</td>\n",
       "      <td>34.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>181487</th>\n",
       "      <td>I-BC-L9780-21</td>\n",
       "      <td>34.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77218</th>\n",
       "      <td>I-BC-L9780-21</td>\n",
       "      <td>34.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77129</th>\n",
       "      <td>I-BC-L9780-21</td>\n",
       "      <td>34.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77017</th>\n",
       "      <td>I-BC-L9780-21</td>\n",
       "      <td>34.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77016</th>\n",
       "      <td>I-BC-L9780-21</td>\n",
       "      <td>34.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69047</th>\n",
       "      <td>I-BC-L9780-21</td>\n",
       "      <td>34.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69000</th>\n",
       "      <td>I-BC-L9780-21</td>\n",
       "      <td>34.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68954</th>\n",
       "      <td>I-BC-L9780-21</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>181391</th>\n",
       "      <td>I-BC-L9780-21</td>\n",
       "      <td>34.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>181641</th>\n",
       "      <td>I-BC-L9780-21</td>\n",
       "      <td>34.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>181538</th>\n",
       "      <td>I-BC-L9780-21</td>\n",
       "      <td>34.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>205748</th>\n",
       "      <td>I-BC-L9780-21</td>\n",
       "      <td>34.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>216333</th>\n",
       "      <td>I-BC-L9780-21</td>\n",
       "      <td>34.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>210775</th>\n",
       "      <td>I-BC-L9780-21</td>\n",
       "      <td>34.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>210578</th>\n",
       "      <td>I-BC-L9780-21</td>\n",
       "      <td>34.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>210577</th>\n",
       "      <td>I-BC-L9780-21</td>\n",
       "      <td>34.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>210576</th>\n",
       "      <td>I-BC-L9780-21</td>\n",
       "      <td>34.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>205633</th>\n",
       "      <td>I-BC-L9780-21</td>\n",
       "      <td>34.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>205634</th>\n",
       "      <td>I-BC-L9780-21</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>210575</th>\n",
       "      <td>I-BC-L9780-21</td>\n",
       "      <td>34.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>205836</th>\n",
       "      <td>I-BC-L9780-21</td>\n",
       "      <td>34.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>162120</th>\n",
       "      <td>I-BC-L9780-32</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>173187</th>\n",
       "      <td>I-BC-L9780-32</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62436</th>\n",
       "      <td>I2789LL4402W</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62435</th>\n",
       "      <td>I2789LL4402W</td>\n",
       "      <td>40.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62287</th>\n",
       "      <td>I2789LL4402W</td>\n",
       "      <td>40.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62184</th>\n",
       "      <td>I2789LL4402W</td>\n",
       "      <td>40.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62183</th>\n",
       "      <td>I2789LL4402W</td>\n",
       "      <td>40.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>216379</th>\n",
       "      <td>I2792LL4402W</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>126824</th>\n",
       "      <td>I33-9578</td>\n",
       "      <td>3.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>190252</th>\n",
       "      <td>I33-9578</td>\n",
       "      <td>3.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>190292</th>\n",
       "      <td>I33-9578</td>\n",
       "      <td>3.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>147963</th>\n",
       "      <td>I33-9578</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>147807</th>\n",
       "      <td>I33-9578</td>\n",
       "      <td>3.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>126882</th>\n",
       "      <td>I33-9578</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>190337</th>\n",
       "      <td>I33-9578</td>\n",
       "      <td>3.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>190150</th>\n",
       "      <td>I33-9578</td>\n",
       "      <td>3.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>126823</th>\n",
       "      <td>I33-9578</td>\n",
       "      <td>3.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4905</th>\n",
       "      <td>I33-9578</td>\n",
       "      <td>3.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>126677</th>\n",
       "      <td>I33-9578</td>\n",
       "      <td>3.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4954</th>\n",
       "      <td>I33-9578</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5118</th>\n",
       "      <td>I33-9578</td>\n",
       "      <td>3.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5172</th>\n",
       "      <td>I33-9578</td>\n",
       "      <td>3.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5173</th>\n",
       "      <td>I33-9578</td>\n",
       "      <td>3.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5223</th>\n",
       "      <td>I33-9578</td>\n",
       "      <td>3.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5224</th>\n",
       "      <td>I33-9578</td>\n",
       "      <td>3.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5225</th>\n",
       "      <td>I33-9578</td>\n",
       "      <td>3.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23888</th>\n",
       "      <td>I33-9578</td>\n",
       "      <td>3.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23889</th>\n",
       "      <td>I33-9578</td>\n",
       "      <td>3.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>126778</th>\n",
       "      <td>I33-9578</td>\n",
       "      <td>3.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24038</th>\n",
       "      <td>I33-9578</td>\n",
       "      <td>3.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24092</th>\n",
       "      <td>I33-9578</td>\n",
       "      <td>3.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23948</th>\n",
       "      <td>I33-9578</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92448</th>\n",
       "      <td>I33-9578</td>\n",
       "      <td>3.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>126618</th>\n",
       "      <td>I33-9578</td>\n",
       "      <td>3.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>126617</th>\n",
       "      <td>I33-9578</td>\n",
       "      <td>3.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>126616</th>\n",
       "      <td>I33-9578</td>\n",
       "      <td>3.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>121047</th>\n",
       "      <td>I33-9578</td>\n",
       "      <td>3.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92728</th>\n",
       "      <td>I33-9578</td>\n",
       "      <td>3.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92447</th>\n",
       "      <td>I33-9578</td>\n",
       "      <td>3.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92629</th>\n",
       "      <td>I33-9578</td>\n",
       "      <td>3.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92574</th>\n",
       "      <td>I33-9578</td>\n",
       "      <td>3.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92480</th>\n",
       "      <td>I33-9578</td>\n",
       "      <td>3.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>126619</th>\n",
       "      <td>I33-9578</td>\n",
       "      <td>3.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201988</th>\n",
       "      <td>W3427X3148Z3N</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>165583</th>\n",
       "      <td>XV4NM455W4</td>\n",
       "      <td>24.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>165531</th>\n",
       "      <td>XV4NM455W4</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>165478</th>\n",
       "      <td>XV4NM455W4</td>\n",
       "      <td>24.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>193331</th>\n",
       "      <td>Z14-8458-233352</td>\n",
       "      <td>255.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>193266</th>\n",
       "      <td>Z14-8458-233352</td>\n",
       "      <td>255.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>193207</th>\n",
       "      <td>Z14-8458-233352</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>193035</th>\n",
       "      <td>Z14-8458-233352</td>\n",
       "      <td>255.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>193332</th>\n",
       "      <td>Z14-8458-233352</td>\n",
       "      <td>255.5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                item_id  part_cost\n",
       "45055        28243-6CN2        NaN\n",
       "68816     I-BC-L9780-21       34.0\n",
       "181487    I-BC-L9780-21       34.0\n",
       "77218     I-BC-L9780-21       34.0\n",
       "77129     I-BC-L9780-21       34.0\n",
       "77017     I-BC-L9780-21       34.0\n",
       "77016     I-BC-L9780-21       34.0\n",
       "69047     I-BC-L9780-21       34.0\n",
       "69000     I-BC-L9780-21       34.0\n",
       "68954     I-BC-L9780-21        NaN\n",
       "181391    I-BC-L9780-21       34.0\n",
       "181641    I-BC-L9780-21       34.0\n",
       "181538    I-BC-L9780-21       34.0\n",
       "205748    I-BC-L9780-21       34.0\n",
       "216333    I-BC-L9780-21       34.0\n",
       "210775    I-BC-L9780-21       34.0\n",
       "210578    I-BC-L9780-21       34.0\n",
       "210577    I-BC-L9780-21       34.0\n",
       "210576    I-BC-L9780-21       34.0\n",
       "205633    I-BC-L9780-21       34.0\n",
       "205634    I-BC-L9780-21        NaN\n",
       "210575    I-BC-L9780-21       34.0\n",
       "205836    I-BC-L9780-21       34.0\n",
       "162120    I-BC-L9780-32        NaN\n",
       "173187    I-BC-L9780-32        NaN\n",
       "62436      I2789LL4402W        NaN\n",
       "62435      I2789LL4402W       40.0\n",
       "62287      I2789LL4402W       40.0\n",
       "62184      I2789LL4402W       40.0\n",
       "62183      I2789LL4402W       40.0\n",
       "216379     I2792LL4402W        NaN\n",
       "126824         I33-9578        3.1\n",
       "190252         I33-9578        3.1\n",
       "190292         I33-9578        3.1\n",
       "147963         I33-9578        NaN\n",
       "147807         I33-9578        3.1\n",
       "126882         I33-9578        NaN\n",
       "190337         I33-9578        3.1\n",
       "190150         I33-9578        3.1\n",
       "126823         I33-9578        3.1\n",
       "4905           I33-9578        3.1\n",
       "126677         I33-9578        3.1\n",
       "4954           I33-9578        NaN\n",
       "5118           I33-9578        3.1\n",
       "5172           I33-9578        3.1\n",
       "5173           I33-9578        3.1\n",
       "5223           I33-9578        3.1\n",
       "5224           I33-9578        3.1\n",
       "5225           I33-9578        3.1\n",
       "23888          I33-9578        3.1\n",
       "23889          I33-9578        3.1\n",
       "126778         I33-9578        3.1\n",
       "24038          I33-9578        3.1\n",
       "24092          I33-9578        3.1\n",
       "23948          I33-9578        NaN\n",
       "92448          I33-9578        3.1\n",
       "126618         I33-9578        3.1\n",
       "126617         I33-9578        3.1\n",
       "126616         I33-9578        3.1\n",
       "121047         I33-9578        3.1\n",
       "92728          I33-9578        3.1\n",
       "92447          I33-9578        3.1\n",
       "92629          I33-9578        3.1\n",
       "92574          I33-9578        3.1\n",
       "92480          I33-9578        3.1\n",
       "126619         I33-9578        3.1\n",
       "201988    W3427X3148Z3N        NaN\n",
       "165583       XV4NM455W4       24.6\n",
       "165531       XV4NM455W4        NaN\n",
       "165478       XV4NM455W4       24.6\n",
       "193331  Z14-8458-233352      255.5\n",
       "193266  Z14-8458-233352      255.5\n",
       "193207  Z14-8458-233352        NaN\n",
       "193035  Z14-8458-233352      255.5\n",
       "193332  Z14-8458-233352      255.5"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# checking which item_id are missing part_cost values\n",
    "\n",
    "list = list(data[data['part_cost'].isna()][\"item_id\"])\n",
    "\n",
    "data[data[\"item_id\"].isin(list)][[\"item_id\",\"part_cost\"\n",
    "                                 ]].sort_values(by=['item_id'])\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5680183c-f6dd-489b-bb70-cb6cdbd36605",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dictionary of known part_cost values\n",
    "fill_values = {\n",
    "    '28243-6CN2': 0.1,\n",
    "    'Z14-8458-233352': 255.5,\n",
    "    'I-BC-L9780-21': 34.0,\n",
    "    'I-BC-L9780-32': 0.1,\n",
    "    'I2789LL4402W': 40.0,\n",
    "    'I33-9578': 3.1,\n",
    "    'W3427X3148Z3N': 0.1,\n",
    "    'XV4NM455W4': 24.6,\n",
    "}\n",
    "\n",
    "# Fill missing part_cost values\n",
    "for item_id in list:\n",
    "    if item_id in fill_values:\n",
    "        data.loc[data['item_id'] == item_id, 'part_cost'] = fill_values[item_id]\n",
    "    else:\n",
    "        data.loc[data['item_id'] == item_id, 'part_cost'] = 0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "85954213",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ID                           0.0\n",
       "suggestion_dt                0.0\n",
       "expid                        0.0\n",
       "expid_desc                   0.0\n",
       "item_id                      0.0\n",
       "pdc                          0.0\n",
       "vndr_concat                  0.0\n",
       "desk                         0.0\n",
       "velocity                     0.0\n",
       "part_cost                    0.0\n",
       "spq                          0.0\n",
       "ord_min                      0.0\n",
       "ord_mult                     0.0\n",
       "ord_dollar_min               0.0\n",
       "lead_time                    0.0\n",
       "on_hand                      0.0\n",
       "on_order                     0.0\n",
       "ss_units_left_pct            0.0\n",
       "max_oh_left_pct              0.0\n",
       "days_on_hand                 0.0\n",
       "oh_oo_sug_dos                0.0\n",
       "oo_dos                       0.0\n",
       "doh_less_ss                  0.0\n",
       "doh_to_ltm                   0.0\n",
       "oo_it_portion                0.0\n",
       "oh_5d_change                12.0\n",
       "min_on_hand_change_5d        8.0\n",
       "days_below_ss                0.0\n",
       "fcst_3m                      0.0\n",
       "fcst_daily                   0.0\n",
       "supplier_past_due_pct        2.0\n",
       "ots_pct                      4.0\n",
       "early_ratio                  4.0\n",
       "on_time_ratio                4.0\n",
       "no_ship_ratio                4.0\n",
       "dmd_rolling_90d              4.0\n",
       "dmd_fcst_portion             4.0\n",
       "orders_12m                   0.0\n",
       "dmd_wkly_95pct               2.0\n",
       "dmd_wkly_dos                 2.0\n",
       "mdi_stockouts               12.0\n",
       "network_avail               12.0\n",
       "ltm_median                   5.0\n",
       "ltm_75pct                    5.0\n",
       "ltm_90pct                    5.0\n",
       "ltm_90pct_difference_wks     5.0\n",
       "rhit_within_2wks             0.0\n",
       "rhit_label                   0.0\n",
       "dtype: float64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "round((data.isna().sum()*100)/len(data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6c5dc0d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row: ord_min, Column: ord_mult, Correlation: 0.9930256896635035\n",
      "Row: ord_mult, Column: ord_min, Correlation: 0.9930256896635035\n",
      "Row: on_hand, Column: fcst_3m, Correlation: 0.8739086373372763\n",
      "Row: on_hand, Column: fcst_daily, Correlation: 0.8739086373547202\n",
      "Row: on_hand, Column: dmd_rolling_90d, Correlation: 0.8011029205656477\n",
      "Row: on_hand, Column: dmd_wkly_95pct, Correlation: 0.7175333937946996\n",
      "Row: on_order, Column: fcst_3m, Correlation: 0.8924784458734565\n",
      "Row: on_order, Column: fcst_daily, Correlation: 0.8924784458622969\n",
      "Row: on_order, Column: dmd_rolling_90d, Correlation: 0.875674851123055\n",
      "Row: on_order, Column: dmd_wkly_95pct, Correlation: 0.8820036093476467\n",
      "Row: ss_units_left_pct, Column: max_oh_left_pct, Correlation: 0.8167377153463792\n",
      "Row: max_oh_left_pct, Column: ss_units_left_pct, Correlation: 0.8167377153463792\n",
      "Row: days_on_hand, Column: doh_to_ltm, Correlation: 0.8003150665981928\n",
      "Row: doh_to_ltm, Column: days_on_hand, Correlation: 0.8003150665981928\n",
      "Row: fcst_3m, Column: on_hand, Correlation: 0.8739086373372763\n",
      "Row: fcst_3m, Column: on_order, Correlation: 0.8924784458734565\n",
      "Row: fcst_3m, Column: fcst_daily, Correlation: 0.9999999999999915\n",
      "Row: fcst_3m, Column: dmd_rolling_90d, Correlation: 0.949598235690248\n",
      "Row: fcst_3m, Column: dmd_wkly_95pct, Correlation: 0.8836689608233264\n",
      "Row: fcst_daily, Column: on_hand, Correlation: 0.8739086373547202\n",
      "Row: fcst_daily, Column: on_order, Correlation: 0.8924784458622969\n",
      "Row: fcst_daily, Column: fcst_3m, Correlation: 0.9999999999999915\n",
      "Row: fcst_daily, Column: dmd_rolling_90d, Correlation: 0.9495982356714381\n",
      "Row: fcst_daily, Column: dmd_wkly_95pct, Correlation: 0.883668960824903\n",
      "Row: supplier_past_due_pct, Column: ots_pct, Correlation: -0.7426561567596486\n",
      "Row: ots_pct, Column: supplier_past_due_pct, Correlation: -0.7426561567596486\n",
      "Row: dmd_rolling_90d, Column: on_hand, Correlation: 0.8011029205656477\n",
      "Row: dmd_rolling_90d, Column: on_order, Correlation: 0.875674851123055\n",
      "Row: dmd_rolling_90d, Column: fcst_3m, Correlation: 0.949598235690248\n",
      "Row: dmd_rolling_90d, Column: fcst_daily, Correlation: 0.9495982356714381\n",
      "Row: dmd_rolling_90d, Column: dmd_wkly_95pct, Correlation: 0.8677910791316135\n",
      "Row: dmd_wkly_95pct, Column: on_hand, Correlation: 0.7175333937946996\n",
      "Row: dmd_wkly_95pct, Column: on_order, Correlation: 0.8820036093476467\n",
      "Row: dmd_wkly_95pct, Column: fcst_3m, Correlation: 0.8836689608233264\n",
      "Row: dmd_wkly_95pct, Column: fcst_daily, Correlation: 0.883668960824903\n",
      "Row: dmd_wkly_95pct, Column: dmd_rolling_90d, Correlation: 0.8677910791316135\n",
      "Row: ltm_median, Column: ltm_75pct, Correlation: 0.9223004513909602\n",
      "Row: ltm_75pct, Column: ltm_median, Correlation: 0.9223004513909602\n",
      "Row: ltm_75pct, Column: ltm_90pct, Correlation: 0.7536500346025833\n",
      "Row: ltm_90pct, Column: ltm_75pct, Correlation: 0.7536500346025833\n",
      "Row: ltm_90pct, Column: ltm_90pct_difference_wks, Correlation: 0.8671345277787273\n",
      "Row: ltm_90pct_difference_wks, Column: ltm_90pct, Correlation: 0.8671345277787273\n"
     ]
    }
   ],
   "source": [
    "correlation_matrix = data.corr(numeric_only = True)\n",
    "\n",
    "for row in correlation_matrix.index:\n",
    "    for col in correlation_matrix.columns:\n",
    "        correlation_value = correlation_matrix.loc[row, col]\n",
    "        if (abs(correlation_value) > 0.7) & (abs(correlation_value) < 1):\n",
    "            print(f\"Row: {row}, Column: {col}, Correlation: {correlation_value}\")\n",
    "            "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d4b029a-a7fb-4caa-8fe9-a5e8019a5624",
   "metadata": {},
   "source": [
    "#### Dropping identifiers and those that have high correlation factors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "43df3efa",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.drop(['ID', 'suggestion_dt','item_id','vndr_concat', \n",
    "           'expid', 'expid_desc','ord_mult', 'fcst_daily',\n",
    "           'on_hand', 'on_order','max_oh_left_pct','doh_to_ltm',\n",
    "           'dmd_rolling_90d','dmd_wkly_95pct',\n",
    "           'ltm_90pct_difference_wks','ltm_75pct'], \n",
    "          axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2ce97d85",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['pdc', 'desk', 'velocity', 'part_cost', 'spq', 'ord_min',\n",
       "       'ord_dollar_min', 'lead_time', 'ss_units_left_pct', 'days_on_hand',\n",
       "       'oh_oo_sug_dos', 'oo_dos', 'doh_less_ss', 'oo_it_portion',\n",
       "       'oh_5d_change', 'min_on_hand_change_5d', 'days_below_ss', 'fcst_3m',\n",
       "       'supplier_past_due_pct', 'ots_pct', 'early_ratio', 'on_time_ratio',\n",
       "       'no_ship_ratio', 'dmd_fcst_portion', 'orders_12m', 'dmd_wkly_dos',\n",
       "       'mdi_stockouts', 'network_avail', 'ltm_median', 'ltm_90pct',\n",
       "       'rhit_within_2wks', 'rhit_label'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4be84398-4d54-412e-8c39-2560abc01e4f",
   "metadata": {},
   "source": [
    "#### Recheck the correlation factors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "35550ac1",
   "metadata": {},
   "outputs": [],
   "source": [
    "correlation_matrix = data.corr(numeric_only = True)\n",
    "\n",
    "for row in correlation_matrix.index:\n",
    "    for col in correlation_matrix.columns:\n",
    "        correlation_value = correlation_matrix.loc[row, col]\n",
    "        if (abs(correlation_value) > 0.75) & (abs(correlation_value) < 1):\n",
    "            print(f\"Row: {row}, Column: {col}, Correlation: {correlation_value}\")\n",
    "            "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe67d1a6-a4c5-4faf-b0f2-b79705755fc4",
   "metadata": {},
   "source": [
    "#### Checking data types to make the data ready for modelling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "08ddb46a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pdc                       object\n",
       "desk                      object\n",
       "velocity                  object\n",
       "part_cost                float64\n",
       "spq                        int64\n",
       "ord_min                    int64\n",
       "ord_dollar_min             int64\n",
       "lead_time                  int64\n",
       "ss_units_left_pct        float64\n",
       "days_on_hand             float64\n",
       "oh_oo_sug_dos            float64\n",
       "oo_dos                   float64\n",
       "doh_less_ss                int64\n",
       "oo_it_portion            float64\n",
       "oh_5d_change             float64\n",
       "min_on_hand_change_5d    float64\n",
       "days_below_ss              int64\n",
       "fcst_3m                  float64\n",
       "supplier_past_due_pct    float64\n",
       "ots_pct                  float64\n",
       "early_ratio              float64\n",
       "on_time_ratio            float64\n",
       "no_ship_ratio            float64\n",
       "dmd_fcst_portion         float64\n",
       "orders_12m               float64\n",
       "dmd_wkly_dos             float64\n",
       "mdi_stockouts            float64\n",
       "network_avail            float64\n",
       "ltm_median               float64\n",
       "ltm_90pct                float64\n",
       "rhit_within_2wks           int64\n",
       "rhit_label                 int64\n",
       "dtype: object"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "95ac89ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "object_columns = data.select_dtypes(include='object').columns\n",
    "data[object_columns] = data[object_columns].astype('string')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f22291af",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pdc                      string[python]\n",
       "desk                     string[python]\n",
       "velocity                 string[python]\n",
       "part_cost                       float64\n",
       "spq                               int64\n",
       "ord_min                           int64\n",
       "ord_dollar_min                    int64\n",
       "lead_time                         int64\n",
       "ss_units_left_pct               float64\n",
       "days_on_hand                    float64\n",
       "oh_oo_sug_dos                   float64\n",
       "oo_dos                          float64\n",
       "doh_less_ss                       int64\n",
       "oo_it_portion                   float64\n",
       "oh_5d_change                    float64\n",
       "min_on_hand_change_5d           float64\n",
       "days_below_ss                     int64\n",
       "fcst_3m                         float64\n",
       "supplier_past_due_pct           float64\n",
       "ots_pct                         float64\n",
       "early_ratio                     float64\n",
       "on_time_ratio                   float64\n",
       "no_ship_ratio                   float64\n",
       "dmd_fcst_portion                float64\n",
       "orders_12m                      float64\n",
       "dmd_wkly_dos                    float64\n",
       "mdi_stockouts                   float64\n",
       "network_avail                   float64\n",
       "ltm_median                      float64\n",
       "ltm_90pct                       float64\n",
       "rhit_within_2wks                  int64\n",
       "rhit_label                        int64\n",
       "dtype: object"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e6ef3b3-0dc2-4a07-ac43-daf74eb56eaf",
   "metadata": {},
   "source": [
    "#### Converting velocity parameter into int, by using cat.codes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ddd184bb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "velocity\n",
       "3    80326\n",
       "2    51233\n",
       "N    36771\n",
       "9    24935\n",
       "1    21208\n",
       "M    14280\n",
       "L    14000\n",
       "T      685\n",
       "A      656\n",
       "S       25\n",
       "8       15\n",
       "E        3\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.value_counts('velocity')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "bfa45a2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "data['velocity'] = np.where(data['velocity'] == '8', 4, \n",
    "                              np.where(data['velocity'] == '9', 5,\n",
    "                                       np.where(data['velocity'] == 'A', 6, \n",
    "                                               np.where(data['velocity'] == 'E', 7,\n",
    "                                                       np.where(data['velocity'] == 'L', 8,\n",
    "                                                                np.where(data['velocity'] == 'M', 9,\n",
    "                                                                         np.where(data['velocity'] == 'N', 10,\n",
    "                                                                                  np.where(data['velocity'] == 'S', 11,\n",
    "                                                                                           np.where(data['velocity'] == 'T', 12,\n",
    "                                                                                                   data['velocity'])))))))))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c4fef7ac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "velocity\n",
       "3     80326\n",
       "2     51233\n",
       "10    36771\n",
       "5     24935\n",
       "1     21208\n",
       "9     14280\n",
       "8     14000\n",
       "12      685\n",
       "6       656\n",
       "11       25\n",
       "4        15\n",
       "7         3\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.value_counts('velocity')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "75d3cfc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "data['pdc'] = data['pdc'].astype('category').cat.codes\n",
    "data['desk'] = data['desk'].astype('category').cat.codes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "afc45b57",
   "metadata": {},
   "outputs": [],
   "source": [
    "object_columns = data.select_dtypes(include='object').columns\n",
    "data[object_columns] = data[object_columns].astype('int64')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "0dbdeff6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pdc                         int8\n",
       "desk                        int8\n",
       "velocity                   int64\n",
       "part_cost                float64\n",
       "spq                        int64\n",
       "ord_min                    int64\n",
       "ord_dollar_min             int64\n",
       "lead_time                  int64\n",
       "ss_units_left_pct        float64\n",
       "days_on_hand             float64\n",
       "oh_oo_sug_dos            float64\n",
       "oo_dos                   float64\n",
       "doh_less_ss                int64\n",
       "oo_it_portion            float64\n",
       "oh_5d_change             float64\n",
       "min_on_hand_change_5d    float64\n",
       "days_below_ss              int64\n",
       "fcst_3m                  float64\n",
       "supplier_past_due_pct    float64\n",
       "ots_pct                  float64\n",
       "early_ratio              float64\n",
       "on_time_ratio            float64\n",
       "no_ship_ratio            float64\n",
       "dmd_fcst_portion         float64\n",
       "orders_12m               float64\n",
       "dmd_wkly_dos             float64\n",
       "mdi_stockouts            float64\n",
       "network_avail            float64\n",
       "ltm_median               float64\n",
       "ltm_90pct                float64\n",
       "rhit_within_2wks           int64\n",
       "rhit_label                 int64\n",
       "dtype: object"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "7634b6b3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pdc                       0.0\n",
       "desk                      0.0\n",
       "velocity                  0.0\n",
       "part_cost                 0.0\n",
       "spq                       0.0\n",
       "ord_min                   0.0\n",
       "ord_dollar_min            0.0\n",
       "lead_time                 0.0\n",
       "ss_units_left_pct         0.0\n",
       "days_on_hand              0.0\n",
       "oh_oo_sug_dos             0.0\n",
       "oo_dos                    0.0\n",
       "doh_less_ss               0.0\n",
       "oo_it_portion             0.0\n",
       "oh_5d_change             12.0\n",
       "min_on_hand_change_5d     8.0\n",
       "days_below_ss             0.0\n",
       "fcst_3m                   0.0\n",
       "supplier_past_due_pct     2.0\n",
       "ots_pct                   4.0\n",
       "early_ratio               4.0\n",
       "on_time_ratio             4.0\n",
       "no_ship_ratio             4.0\n",
       "dmd_fcst_portion          4.0\n",
       "orders_12m                0.0\n",
       "dmd_wkly_dos              2.0\n",
       "mdi_stockouts            12.0\n",
       "network_avail            12.0\n",
       "ltm_median                5.0\n",
       "ltm_90pct                 5.0\n",
       "rhit_within_2wks          0.0\n",
       "rhit_label                0.0\n",
       "dtype: float64"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "round((data.isna().sum()*100)/len(data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "be6b36e2-731f-4f70-9542-0eb4de21c399",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 pdc           desk       velocity      part_cost  \\\n",
      "count  244137.000000  244137.000000  244137.000000  244137.000000   \n",
      "mean        3.983960       8.420883       4.546910     120.543420   \n",
      "std         2.843953       4.938374       3.122622     323.798665   \n",
      "min         0.000000       0.000000       1.000000       0.000000   \n",
      "25%         1.000000       4.000000       2.000000       7.700000   \n",
      "50%         3.000000       9.000000       3.000000      27.600000   \n",
      "75%         6.000000      12.000000       8.000000      95.900000   \n",
      "max         9.000000      16.000000      12.000000   16823.500000   \n",
      "\n",
      "                 spq        ord_min  ord_dollar_min      lead_time  \\\n",
      "count  244137.000000  244137.000000   244137.000000  244137.000000   \n",
      "mean        2.197123       4.631240        0.105302      43.569311   \n",
      "std        10.454645      43.710326        3.422129      24.865670   \n",
      "min         1.000000       0.000000        0.000000       7.000000   \n",
      "25%         1.000000       0.000000        0.000000      25.000000   \n",
      "50%         1.000000       0.000000        0.000000      38.000000   \n",
      "75%         1.000000       0.000000        0.000000      53.000000   \n",
      "max       500.000000    3600.000000      250.000000     243.000000   \n",
      "\n",
      "       ss_units_left_pct   days_on_hand  oh_oo_sug_dos         oo_dos  \\\n",
      "count      243792.000000  244137.000000  244137.000000  244137.000000   \n",
      "mean            0.960139      34.480534     107.615142      34.997414   \n",
      "std             1.556578      40.761099      48.101319      37.989389   \n",
      "min           -82.266910    -360.271263    -135.875426       0.000000   \n",
      "25%             0.089759       2.676747      76.026356       0.000000   \n",
      "50%             0.894748      30.582598      97.982291      28.140167   \n",
      "75%             1.507094      55.448310     127.197733      50.483803   \n",
      "max           166.759311    2334.630350    2480.544747     364.570807   \n",
      "\n",
      "         doh_less_ss  oo_it_portion   oh_5d_change  min_on_hand_change_5d  \\\n",
      "count  244137.000000  244137.000000  213631.000000          224447.000000   \n",
      "mean        0.543629       0.222292      -0.259877              -0.401907   \n",
      "std         0.498094       0.369384       1.282587               1.309047   \n",
      "min         0.000000       0.000000    -250.000000            -462.916667   \n",
      "25%         0.000000       0.000000      -0.500000              -0.500000   \n",
      "50%         1.000000       0.000000      -0.250000              -0.258824   \n",
      "75%         1.000000       0.372093       0.000000              -0.085106   \n",
      "max         1.000000       1.000000     120.900000              82.500000   \n",
      "\n",
      "       days_below_ss        fcst_3m  supplier_past_due_pct        ots_pct  \\\n",
      "count  244137.000000  244137.000000          239147.000000  234816.000000   \n",
      "mean        9.563511      92.662505               0.119740       0.663080   \n",
      "std        11.011825    1149.740348               0.142149       0.291952   \n",
      "min         0.000000       0.501900               0.000000       0.000000   \n",
      "25%         0.000000       5.568800               0.014851       0.428571   \n",
      "50%         4.000000      11.969600               0.065574       0.714286   \n",
      "75%        19.000000      34.688700               0.172414       0.934286   \n",
      "max        30.000000  162574.487300               1.000000       1.000000   \n",
      "\n",
      "         early_ratio  on_time_ratio  no_ship_ratio  dmd_fcst_portion  \\\n",
      "count  235468.000000  235468.000000  235468.000000     234413.000000   \n",
      "mean        0.445815       0.340924       0.167860          1.074519   \n",
      "std         0.357622       0.299731       0.267164          2.239476   \n",
      "min         0.000000       0.000000       0.000000          0.003827   \n",
      "25%         0.111111       0.063492       0.000000          0.698417   \n",
      "50%         0.393939       0.291667       0.000000          0.962849   \n",
      "75%         0.777778       0.534884       0.241518          1.277086   \n",
      "max         1.000000       1.000000       1.000000        438.851836   \n",
      "\n",
      "          orders_12m   dmd_wkly_dos  mdi_stockouts  network_avail  \\\n",
      "count  244123.000000  239216.000000  214896.000000  214896.000000   \n",
      "mean       60.936483      11.367758       3.217510       0.922101   \n",
      "std       134.143508      15.314807       9.837333       0.162957   \n",
      "min        -2.000000    -749.000000       0.000000       0.000000   \n",
      "25%        10.000000       1.346154       0.000000       0.923077   \n",
      "50%        21.000000       7.176932       1.000000       0.981481   \n",
      "75%        50.000000      16.333333       3.000000       1.000000   \n",
      "max      2892.000000     558.250000     349.000000       1.000000   \n",
      "\n",
      "          ltm_median      ltm_90pct  rhit_within_2wks     rhit_label  \n",
      "count  233134.000000  233134.000000     244137.000000  244137.000000  \n",
      "mean       30.561405      39.964477          0.140245       0.307381  \n",
      "std        27.055032      47.973101          0.347242       0.461409  \n",
      "min         1.000000       1.000000          0.000000       0.000000  \n",
      "25%        14.500000      19.400000          0.000000       0.000000  \n",
      "50%        23.000000      32.000000          0.000000       0.000000  \n",
      "75%        38.000000      50.000000          0.000000       1.000000  \n",
      "max      3660.000000    3681.400000          1.000000       1.000000  \n"
     ]
    }
   ],
   "source": [
    "print(data.describe())\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79953b0a-42ab-4c53-99fb-7dbd2e37dd72",
   "metadata": {},
   "source": [
    "#### Missing values are filled with 0.01, an insignificant valye, and then we shall check if summary statistics have changed much"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "3b0a11aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.fillna(0.01, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "d024565f-161b-40b8-b3ad-625ce3a17b79",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 pdc           desk       velocity      part_cost  \\\n",
      "count  244137.000000  244137.000000  244137.000000  244137.000000   \n",
      "mean        3.983960       8.420883       4.546910     120.543420   \n",
      "std         2.843953       4.938374       3.122622     323.798665   \n",
      "min         0.000000       0.000000       1.000000       0.000000   \n",
      "25%         1.000000       4.000000       2.000000       7.700000   \n",
      "50%         3.000000       9.000000       3.000000      27.600000   \n",
      "75%         6.000000      12.000000       8.000000      95.900000   \n",
      "max         9.000000      16.000000      12.000000   16823.500000   \n",
      "\n",
      "                 spq        ord_min  ord_dollar_min      lead_time  \\\n",
      "count  244137.000000  244137.000000   244137.000000  244137.000000   \n",
      "mean        2.197123       4.631240        0.105302      43.569311   \n",
      "std        10.454645      43.710326        3.422129      24.865670   \n",
      "min         1.000000       0.000000        0.000000       7.000000   \n",
      "25%         1.000000       0.000000        0.000000      25.000000   \n",
      "50%         1.000000       0.000000        0.000000      38.000000   \n",
      "75%         1.000000       0.000000        0.000000      53.000000   \n",
      "max       500.000000    3600.000000      250.000000     243.000000   \n",
      "\n",
      "       ss_units_left_pct   days_on_hand  oh_oo_sug_dos         oo_dos  \\\n",
      "count      244137.000000  244137.000000  244137.000000  244137.000000   \n",
      "mean            0.958796      34.480534     107.615142      34.997414   \n",
      "std             1.555887      40.761099      48.101319      37.989389   \n",
      "min           -82.266910    -360.271263    -135.875426       0.000000   \n",
      "25%             0.079300       2.676747      76.026356       0.000000   \n",
      "50%             0.893176      30.582598      97.982291      28.140167   \n",
      "75%             1.505646      55.448310     127.197733      50.483803   \n",
      "max           166.759311    2334.630350    2480.544747     364.570807   \n",
      "\n",
      "         doh_less_ss  oo_it_portion   oh_5d_change  min_on_hand_change_5d  \\\n",
      "count  244137.000000  244137.000000  244137.000000          244137.000000   \n",
      "mean        0.543629       0.222292      -0.226154              -0.368686   \n",
      "std         0.498094       0.369384       1.203095               1.260150   \n",
      "min         0.000000       0.000000    -250.000000            -462.916667   \n",
      "25%         0.000000       0.000000      -0.500000              -0.500000   \n",
      "50%         1.000000       0.000000      -0.181818              -0.250000   \n",
      "75%         1.000000       0.372093       0.000000              -0.017964   \n",
      "max         1.000000       1.000000     120.900000              82.500000   \n",
      "\n",
      "       days_below_ss        fcst_3m  supplier_past_due_pct        ots_pct  \\\n",
      "count  244137.000000  244137.000000          244137.000000  244137.000000   \n",
      "mean        9.563511      92.662505               0.117497       0.638146   \n",
      "std        11.011825    1149.740348               0.141543       0.312481   \n",
      "min         0.000000       0.501900               0.000000       0.000000   \n",
      "25%         0.000000       5.568800               0.012195       0.388188   \n",
      "50%         4.000000      11.969600               0.062284       0.698492   \n",
      "75%        19.000000      34.688700               0.168675       0.928571   \n",
      "max        30.000000  162574.487300               1.000000       1.000000   \n",
      "\n",
      "         early_ratio  on_time_ratio  no_ship_ratio  dmd_fcst_portion  \\\n",
      "count  244137.000000  244137.000000  244137.000000     244137.000000   \n",
      "mean        0.430340       0.329174       0.162255          1.032119   \n",
      "std         0.360356       0.300664       0.263999          2.204276   \n",
      "min         0.000000       0.000000       0.000000          0.003827   \n",
      "25%         0.076923       0.037037       0.000000          0.655481   \n",
      "50%         0.363636       0.272727       0.010000          0.942052   \n",
      "75%         0.750000       0.521008       0.222222          1.258798   \n",
      "max         1.000000       1.000000       1.000000        438.851836   \n",
      "\n",
      "          orders_12m   dmd_wkly_dos  mdi_stockouts  network_avail  \\\n",
      "count  244137.000000  244137.000000  244137.000000  244137.000000   \n",
      "mean       60.932989      11.138823       2.833337       0.812856   \n",
      "std       134.140455      15.243473       9.287999       0.333291   \n",
      "min        -2.000000    -749.000000       0.000000       0.000000   \n",
      "25%        10.000000       0.010000       0.000000       0.857143   \n",
      "50%        21.000000       7.000000       1.000000       0.969697   \n",
      "75%        50.000000      16.041667       2.000000       1.000000   \n",
      "max      2892.000000     558.250000     349.000000       1.000000   \n",
      "\n",
      "          ltm_median      ltm_90pct  rhit_within_2wks     rhit_label  \n",
      "count  244137.000000  244137.000000     244137.000000  244137.000000  \n",
      "mean       29.184485      38.163770          0.140245       0.307381  \n",
      "std        27.187431      47.606717          0.347242       0.461409  \n",
      "min         0.010000       0.010000          0.000000       0.000000  \n",
      "25%        13.500000      17.600000          0.000000       0.000000  \n",
      "50%        22.000000      30.700000          0.000000       0.000000  \n",
      "75%        37.000000      48.699000          0.000000       1.000000  \n",
      "max      3660.000000    3681.400000          1.000000       1.000000  \n"
     ]
    }
   ],
   "source": [
    "print(data.describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9c9d627-1b4d-4255-ab0a-5225681ac40c",
   "metadata": {},
   "source": [
    "No significant change appeared in summary statistics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adfe8367-16f2-46c8-b9da-12e81512ccb5",
   "metadata": {},
   "source": [
    "### Final columns for our analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "f80cc2ab",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['pdc', 'desk', 'velocity', 'part_cost', 'spq', 'ord_min',\n",
       "       'ord_dollar_min', 'lead_time', 'ss_units_left_pct', 'days_on_hand',\n",
       "       'oh_oo_sug_dos', 'oo_dos', 'doh_less_ss', 'oo_it_portion',\n",
       "       'oh_5d_change', 'min_on_hand_change_5d', 'days_below_ss', 'fcst_3m',\n",
       "       'supplier_past_due_pct', 'ots_pct', 'early_ratio', 'on_time_ratio',\n",
       "       'no_ship_ratio', 'dmd_fcst_portion', 'orders_12m', 'dmd_wkly_dos',\n",
       "       'mdi_stockouts', 'network_avail', 'ltm_median', 'ltm_90pct',\n",
       "       'rhit_within_2wks', 'rhit_label'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "13b36ce1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.7917042134294531\n",
      "Precision: 0.7163814180929096\n",
      "Recall: 0.5336028072669124\n",
      "confusion matrix: [[45973  4756]\n",
      " [10500 12013]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier, plot_tree\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score,confusion_matrix\n",
    "\n",
    "X_DT= pd.DataFrame()\n",
    "\n",
    "dataNew = data.drop(['rhit_label','rhit_within_2wks'], axis=1)\n",
    "\n",
    "X_DT= dataNew.copy()\n",
    "\n",
    "y_DT = data['rhit_label']\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Splitting the dataset into training and testing sets\n",
    "X_train_DT, X_test_DT, y_train_DT, y_test_DT = train_test_split(X_DT, y_DT, \n",
    "                                                                test_size= 0.3, \n",
    "                                                                stratify= y_DT,\n",
    "                                                                random_state=42)\n",
    "\n",
    "# from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# scaler = StandardScaler()\n",
    "\n",
    "# X_train_DT = scaler.fit_transform(X_train_DT)\n",
    "\n",
    "# X_test_DT = scaler.transform(X_test_DT)\n",
    "\n",
    "\"\"\"\n",
    "SINCE CLASS IMBALANCE DOES NOT EXIST, NO NEED TO DO oversampling\n",
    "\"\"\"\n",
    "\n",
    "# from imblearn.over_sampling import SMOTE\n",
    "\n",
    "# # ... your code for data preparation (X_DT, y_DT) and train-test split (X_train_DT, X_test_DT, y_train_DT, y_test_DT)\n",
    "\n",
    "# # Oversample the minority class (assuming class 1 is the minority)\n",
    "# smote = SMOTE(sampling_strategy='minority')  # Oversample the minority class\n",
    "\n",
    "# X_train_DT, y_train_DT = smote.fit_resample(X_train_DT, y_train_DT)\n",
    "\n",
    "\n",
    "class_weight = {0: 1, 1: 1}\n",
    "\n",
    "# Creating and fitting the decision tree model\n",
    "dt_classifier = DecisionTreeClassifier(class_weight = class_weight, \n",
    "                                       criterion='gini',\n",
    "                                       max_depth=10, max_features=None, max_leaf_nodes=None,\n",
    "                                       min_samples_leaf=180, min_samples_split=2, min_weight_fraction_leaf=0.0, \n",
    "                                       random_state=100, splitter='best')\n",
    "\n",
    "dt_classifier.fit(X_train_DT, y_train_DT)\n",
    "\n",
    "# Predicting the test set results\n",
    "y_pred_DT = dt_classifier.predict(X_test_DT)\n",
    "\n",
    "# Evaluating the model\n",
    "accuracy = accuracy_score(y_test_DT, y_pred_DT)\n",
    "precision = precision_score(y_test_DT, y_pred_DT, average='binary') \n",
    "recall = recall_score(y_test_DT, y_pred_DT, average='binary') \n",
    "\n",
    "# Printing the evaluation metrics\n",
    "print(f\"Accuracy: {accuracy}\")\n",
    "print(f\"Precision: {precision}\")\n",
    "print(f\"Recall: {recall}\")\n",
    "\n",
    "confMatrix = metrics.confusion_matrix(y_test_DT, y_pred_DT)\n",
    "\n",
    "print(f\"confusion matrix: {confMatrix}\")\n",
    "# plt.figure(figsize=(20,20))\n",
    "# plot_tree(dt_classifier, filled=True, feature_names= ['pdc', 'desk', 'velocity', 'part_cost', 'spq', 'ord_min',\n",
    "#        'ord_dollar_min', 'lead_time', 'ss_units_left_pct', 'days_on_hand',\n",
    "#        'oh_oo_sug_dos', 'oo_dos', 'doh_less_ss', 'oo_it_portion',\n",
    "#        'oh_5d_change', 'min_on_hand_change_5d', 'days_below_ss', 'fcst_3m',\n",
    "#        'supplier_past_due_pct', 'ots_pct', 'early_ratio', 'on_time_ratio',\n",
    "#        'no_ship_ratio', 'dmd_fcst_portion', 'orders_12m', 'dmd_wkly_dos',\n",
    "#        'mdi_stockouts', 'network_avail', 'ltm_median', 'ltm_90pct'], class_names=['no RHIT', 'RHIT'])\n",
    "\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "8d5263cf-e261-48f4-81d5-a75920dfc136",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: xgboost in /opt/anaconda3/lib/python3.11/site-packages (2.0.3)\n",
      "Requirement already satisfied: numpy in /opt/anaconda3/lib/python3.11/site-packages (from xgboost) (1.26.4)\n",
      "Requirement already satisfied: scipy in /opt/anaconda3/lib/python3.11/site-packages (from xgboost) (1.11.4)\n"
     ]
    }
   ],
   "source": [
    "!pip install xgboost"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "753f758d-a02e-485d-9465-95d34800c57c",
   "metadata": {},
   "source": [
    "## Accuracy and Precision figures from this part will be our results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "3c27fe26-1bc6-45cd-9fd1-51c330103ef1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8248818983643265\n",
      "Precision: 0.7674932346606285\n",
      "Recall: 0.6172877892773064\n",
      "Confusion Matrix:\n",
      "[[46519  4210]\n",
      " [ 8616 13897]]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, confusion_matrix\n",
    "\n",
    "# Assuming 'data' is your DataFrame and has been previously defined\n",
    "X_DT = pd.DataFrame()\n",
    "\n",
    "# Dropping target variables from features\n",
    "dataNew = data.drop(['rhit_label', 'rhit_within_2wks'], axis=1)\n",
    "X_DT = dataNew.copy()\n",
    "y_DT = data['rhit_label']\n",
    "\n",
    "# Splitting the dataset into training and testing sets\n",
    "X_train_DT, X_test_DT, y_train_DT, y_test_DT = train_test_split(X_DT, y_DT, \n",
    "                                                                test_size=0.3, \n",
    "                                                                stratify=y_DT, \n",
    "                                                                random_state=42)\n",
    "\n",
    "# Initialize the XGBoost classifier\n",
    "xgb_classifier = XGBClassifier(objective='binary:logistic', \n",
    "                               max_depth=10, \n",
    "                               min_child_weight=180, \n",
    "                               random_state=100, \n",
    "                               use_label_encoder=False, \n",
    "                               eval_metric='logloss')\n",
    "\n",
    "# Train the XGBoost model\n",
    "xgb_classifier.fit(X_train_DT, y_train_DT)\n",
    "\n",
    "# Predicting the test set results\n",
    "y_pred_DT = xgb_classifier.predict(X_test_DT)\n",
    "\n",
    "# Evaluating the model\n",
    "accuracy = accuracy_score(y_test_DT, y_pred_DT)\n",
    "precision = precision_score(y_test_DT, y_pred_DT, average='binary')\n",
    "recall = recall_score(y_test_DT, y_pred_DT, average='binary')\n",
    "\n",
    "# Printing the evaluation metrics\n",
    "print(f\"Accuracy: {accuracy}\")\n",
    "print(f\"Precision: {precision}\")\n",
    "print(f\"Recall: {recall}\")\n",
    "\n",
    "# Confusion matrix\n",
    "confMatrix = confusion_matrix(y_test_DT, y_pred_DT)\n",
    "print(f\"Confusion Matrix:\\n{confMatrix}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87ddc572-41ce-472b-8c0d-68605ec88b5e",
   "metadata": {},
   "source": [
    "# Splitting the data to perform a hold-out dataset analysis on our own, to make sure model is robust enough"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0dcdec4a-6c13-45f0-91e8-77d9fd19c869",
   "metadata": {},
   "source": [
    "#### This is only an additional analysis to see how the model is performing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "9d88c3a6-33bd-4627-9d9e-b43b9400dae7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_30, df_70 = train_test_split(data, test_size=0.7, random_state=82)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a170e83-6e2f-4a4c-a759-74f970cb4f2c",
   "metadata": {},
   "source": [
    "### Also checking if the model works similarly across PDC's and Desk's"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "2ceefb9a-e7cb-4d7a-910a-b2c1cb08d3aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overall Accuracy: 0.8248818983643265\n",
      "Overall Precision: 0.7674932346606285\n",
      "Overall Recall: 0.6172877892773064\n",
      "\n",
      "PDC Value: 0\n",
      "Confusion Matrix:\n",
      "[[5436  688]\n",
      " [1185 2266]]\n",
      "Accuracy: 0.8043864229765013\n",
      "Precision: 0.7670954637779283\n",
      "Recall: 0.6566212691973341\n",
      "\n",
      "PDC Value: 9\n",
      "Confusion Matrix:\n",
      "[[3330  265]\n",
      " [ 626  865]]\n",
      "Accuracy: 0.8248132127408573\n",
      "Precision: 0.7654867256637168\n",
      "Recall: 0.5801475519785378\n",
      "\n",
      "PDC Value: 6\n",
      "Confusion Matrix:\n",
      "[[9744  616]\n",
      " [1592 2189]]\n",
      "Accuracy: 0.8438582844211866\n",
      "Precision: 0.7803921568627451\n",
      "Recall: 0.5789473684210527\n",
      "\n",
      "PDC Value: 7\n",
      "Confusion Matrix:\n",
      "[[5134  473]\n",
      " [1069 1547]]\n",
      "Accuracy: 0.8124771981028822\n",
      "Precision: 0.7658415841584159\n",
      "Recall: 0.5913608562691132\n",
      "\n",
      "PDC Value: 4\n",
      "Confusion Matrix:\n",
      "[[368  42]\n",
      " [ 55 186]]\n",
      "Accuracy: 0.8509984639016898\n",
      "Precision: 0.8157894736842105\n",
      "Recall: 0.7717842323651453\n",
      "\n",
      "PDC Value: 3\n",
      "Confusion Matrix:\n",
      "[[5954  647]\n",
      " [1259 2290]]\n",
      "Accuracy: 0.8122167487684729\n",
      "Precision: 0.7797071842015663\n",
      "Recall: 0.6452521837137222\n",
      "\n",
      "PDC Value: 2\n",
      "Confusion Matrix:\n",
      "[[5542  517]\n",
      " [ 981 1750]]\n",
      "Accuracy: 0.8295790671217292\n",
      "Precision: 0.7719453021614469\n",
      "Recall: 0.640790919077261\n",
      "\n",
      "PDC Value: 8\n",
      "Confusion Matrix:\n",
      "[[1992  129]\n",
      " [ 302  356]]\n",
      "Accuracy: 0.8449082403742353\n",
      "Precision: 0.734020618556701\n",
      "Recall: 0.541033434650456\n",
      "\n",
      "PDC Value: 1\n",
      "Confusion Matrix:\n",
      "[[6301  540]\n",
      " [1051 1789]]\n",
      "Accuracy: 0.8356574734015081\n",
      "Precision: 0.7681408329755259\n",
      "Recall: 0.6299295774647887\n",
      "\n",
      "PDC Value: 5\n",
      "Confusion Matrix:\n",
      "[[2718  293]\n",
      " [ 496  659]]\n",
      "Accuracy: 0.8106096975516083\n",
      "Precision: 0.6922268907563025\n",
      "Recall: 0.5705627705627706\n",
      "   pdc_value                  conf_matrix  accuracy  precision    recall\n",
      "0          0  [[5436, 688], [1185, 2266]]  0.804386   0.767095  0.656621\n",
      "1          9    [[3330, 265], [626, 865]]  0.824813   0.765487  0.580148\n",
      "2          6  [[9744, 616], [1592, 2189]]  0.843858   0.780392  0.578947\n",
      "3          7  [[5134, 473], [1069, 1547]]  0.812477   0.765842  0.591361\n",
      "4          4       [[368, 42], [55, 186]]  0.850998   0.815789  0.771784\n",
      "5          3  [[5954, 647], [1259, 2290]]  0.812217   0.779707  0.645252\n",
      "6          2   [[5542, 517], [981, 1750]]  0.829579   0.771945  0.640791\n",
      "7          8    [[1992, 129], [302, 356]]  0.844908   0.734021  0.541033\n",
      "8          1  [[6301, 540], [1051, 1789]]  0.835657   0.768141  0.629930\n",
      "9          5    [[2718, 293], [496, 659]]  0.810610   0.692227  0.570563\n"
     ]
    }
   ],
   "source": [
    "# Assuming 'data' is your DataFrame and has been previously defined\n",
    "X_DT = pd.DataFrame()\n",
    "\n",
    "# Dropping target variables from features\n",
    "dataNew = data.drop(['rhit_label', 'rhit_within_2wks'], axis=1)\n",
    "X_DT = dataNew.copy()\n",
    "y_DT = data['rhit_label']\n",
    "\n",
    "# Splitting the dataset into training and testing sets\n",
    "X_train_DT, X_test_DT, y_train_DT, y_test_DT = train_test_split(X_DT, y_DT, \n",
    "                                                                test_size=0.3, \n",
    "                                                                stratify=y_DT, \n",
    "                                                                random_state=42)\n",
    "\n",
    "# Initialize the XGBoost classifier\n",
    "xgb_classifier = XGBClassifier(objective='binary:logistic', \n",
    "                               max_depth=10, \n",
    "                               min_child_weight=180, \n",
    "                               random_state=100, \n",
    "                               use_label_encoder=False, \n",
    "                               eval_metric='logloss')\n",
    "\n",
    "# Train the XGBoost model\n",
    "xgb_classifier.fit(X_train_DT, y_train_DT)\n",
    "\n",
    "# Predicting the test set results\n",
    "y_pred_DT = xgb_classifier.predict(X_test_DT)\n",
    "\n",
    "# Evaluating the model\n",
    "accuracy = accuracy_score(y_test_DT, y_pred_DT)\n",
    "precision = precision_score(y_test_DT, y_pred_DT, average='binary')\n",
    "recall = recall_score(y_test_DT, y_pred_DT, average='binary')\n",
    "\n",
    "# Printing the evaluation metrics\n",
    "print(f\"Overall Accuracy: {accuracy}\")\n",
    "print(f\"Overall Precision: {precision}\")\n",
    "print(f\"Overall Recall: {recall}\")\n",
    "\n",
    "# Confusion matrix for each unique value in 'pdc'\n",
    "unique_pdc_values = X_test_DT['pdc'].unique()\n",
    "\n",
    "confResults = []\n",
    "\n",
    "for pdc_value in unique_pdc_values:\n",
    "    # Selecting the subset of data where 'pdc' equals the current value\n",
    "    subset_index = X_test_DT[X_test_DT['pdc'] == pdc_value].index\n",
    "    y_test_subset = y_test_DT.loc[subset_index]\n",
    "    \n",
    "    # Predicting the subset of test data\n",
    "    y_pred_subset = xgb_classifier.predict(X_test_DT.loc[subset_index])\n",
    "    \n",
    "    # Calculating confusion matrix\n",
    "    conf_matrix = confusion_matrix(y_test_subset, y_pred_subset)\n",
    "    accuracy = accuracy_score(y_test_subset, y_pred_subset)\n",
    "    precision = precision_score(y_test_subset, y_pred_subset, average='binary')\n",
    "    recall = recall_score(y_test_subset, y_pred_subset, average='binary')\n",
    "    \n",
    "    print(f\"\\nPDC Value: {pdc_value}\")\n",
    "    print(f\"Confusion Matrix:\\n{conf_matrix}\")\n",
    "    print(f\"Accuracy: {accuracy}\")\n",
    "    print(f\"Precision: {precision}\")\n",
    "    print(f\"Recall: {recall}\")\n",
    "    \n",
    "    confResults.append({\n",
    "        'pdc_value': pdc_value,\n",
    "        'conf_matrix': conf_matrix,\n",
    "        'accuracy': accuracy,\n",
    "        'precision': precision,\n",
    "        'recall': recall\n",
    "    })\n",
    "\n",
    "confResults_df = pd.DataFrame(confResults)\n",
    "\n",
    "# Optionally, display the DataFrame\n",
    "print(confResults_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "d98cc547-188a-42a5-abe9-dbcaef706a1b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation on df_70 (70% data):\n",
      "Accuracy: 0.8162827439583374\n",
      "Precision: 0.7592173350582148\n",
      "Recall: 0.5931400416903544\n",
      "Confusion Matrix:\n",
      "[[32460  2978]\n",
      " [ 6441  9390]]\n",
      "Evaluation on df_30 (30% hold-out data):\n",
      "Accuracy: 0.8204284485465791\n",
      "Precision: 0.7563525972565774\n",
      "Recall: 0.6040768678160919\n",
      "Confusion Matrix:\n",
      "[[46635  4334]\n",
      " [ 8818 13454]]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, confusion_matrix\n",
    "\n",
    "# Splitting the data into 70% and 30% for training/initial testing and hold-out\n",
    "df_30, df_70 = train_test_split(data, test_size=0.7, random_state=42)\n",
    "\n",
    "# Prepare the training/initial testing dataset\n",
    "X_70 = df_70.drop(['rhit_label', 'rhit_within_2wks'], axis=1)\n",
    "y_70 = df_70['rhit_label']\n",
    "\n",
    "# Splitting df_70 into training and testing sets\n",
    "X_train_70, X_test_70, y_train_70, y_test_70 = train_test_split(X_70, y_70, \n",
    "                                                                test_size=0.3, \n",
    "                                                                stratify=y_70, \n",
    "                                                                random_state=42)\n",
    "\n",
    "# Initialize the XGBoost classifier\n",
    "xgb_classifier = XGBClassifier(objective='binary:logistic', \n",
    "                               max_depth=10, \n",
    "                               min_child_weight=180, \n",
    "                               random_state=100, \n",
    "                               use_label_encoder=False, \n",
    "                               eval_metric='logloss')\n",
    "\n",
    "# Train the XGBoost model\n",
    "xgb_classifier.fit(X_train_70, y_train_70)\n",
    "\n",
    "# Predicting the test set results for df_70\n",
    "y_pred_70 = xgb_classifier.predict(X_test_70)\n",
    "\n",
    "# Evaluating the model on df_70\n",
    "accuracy_70 = accuracy_score(y_test_70, y_pred_70)\n",
    "precision_70 = precision_score(y_test_70, y_pred_70, average='binary')\n",
    "recall_70 = recall_score(y_test_70, y_pred_70, average='binary')\n",
    "\n",
    "# Printing the evaluation metrics for df_70\n",
    "print(\"Evaluation on df_70 (70% data):\")\n",
    "print(f\"Accuracy: {accuracy_70}\")\n",
    "print(f\"Precision: {precision_70}\")\n",
    "print(f\"Recall: {recall_70}\")\n",
    "\n",
    "# Confusion matrix for df_70\n",
    "conf_matrix_70 = confusion_matrix(y_test_70, y_pred_70)\n",
    "print(f\"Confusion Matrix:\\n{conf_matrix_70}\")\n",
    "\n",
    "# Evaluate the model on df_30 as hold-out data\n",
    "X_30 = df_30.drop(['rhit_label', 'rhit_within_2wks'], axis=1)\n",
    "y_30 = df_30['rhit_label']\n",
    "\n",
    "# Predicting the hold-out set results for df_30\n",
    "y_pred_30 = xgb_classifier.predict(X_30)\n",
    "\n",
    "# Evaluating the model on df_30\n",
    "accuracy_30 = accuracy_score(y_30, y_pred_30)\n",
    "precision_30 = precision_score(y_30, y_pred_30, average='binary')\n",
    "recall_30 = recall_score(y_30, y_pred_30, average='binary')\n",
    "\n",
    "# Printing the evaluation metrics for df_30\n",
    "print(\"Evaluation on df_30 (30% hold-out data):\")\n",
    "print(f\"Accuracy: {accuracy_30}\")\n",
    "print(f\"Precision: {precision_30}\")\n",
    "print(f\"Recall: {recall_30}\")\n",
    "\n",
    "# Confusion matrix for df_30\n",
    "conf_matrix_30 = confusion_matrix(y_30, y_pred_30)\n",
    "print(f\"Confusion Matrix:\\n{conf_matrix_30}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "d3037e31-3ee2-4723-8c61-0aba43a60cd2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation on df_70 (70% data):\n",
      "Accuracy: 0.8162827439583374\n",
      "Precision: 0.7592173350582148\n",
      "Recall: 0.5931400416903544\n",
      "Confusion Matrix:\n",
      "[[32460  2978]\n",
      " [ 6441  9390]]\n",
      "\n",
      "PDC Value: 1\n",
      "Confusion Matrix:\n",
      "[[4418  356]\n",
      " [ 811 1179]]\n",
      "Accuracy: 0.8274689532820816\n",
      "Precision: 0.7680781758957654\n",
      "Recall: 0.592462311557789\n",
      "\n",
      "PDC Value: 0\n",
      "Confusion Matrix:\n",
      "[[3754  480]\n",
      " [ 909 1575]]\n",
      "Accuracy: 0.7932420363203334\n",
      "Precision: 0.7664233576642335\n",
      "Recall: 0.6340579710144928\n",
      "\n",
      "PDC Value: 3\n",
      "Confusion Matrix:\n",
      "[[4232  472]\n",
      " [ 908 1516]]\n",
      "Accuracy: 0.8063973063973064\n",
      "Precision: 0.7625754527162978\n",
      "Recall: 0.6254125412541254\n",
      "\n",
      "PDC Value: 6\n",
      "Confusion Matrix:\n",
      "[[6857  483]\n",
      " [1153 1481]]\n",
      "Accuracy: 0.8359735311810708\n",
      "Precision: 0.7540733197556008\n",
      "Recall: 0.5622627182991647\n",
      "\n",
      "PDC Value: 5\n",
      "Confusion Matrix:\n",
      "[[1878  167]\n",
      " [ 387  418]]\n",
      "Accuracy: 0.8056140350877193\n",
      "Precision: 0.7145299145299145\n",
      "Recall: 0.5192546583850932\n",
      "\n",
      "PDC Value: 2\n",
      "Confusion Matrix:\n",
      "[[3809  364]\n",
      " [ 748 1183]]\n",
      "Accuracy: 0.817824377457405\n",
      "Precision: 0.7647058823529411\n",
      "Recall: 0.6126359399274987\n",
      "\n",
      "PDC Value: 9\n",
      "Confusion Matrix:\n",
      "[[2327  211]\n",
      " [ 496  568]]\n",
      "Accuracy: 0.8037201554691837\n",
      "Precision: 0.7291399229781772\n",
      "Recall: 0.5338345864661654\n",
      "\n",
      "PDC Value: 7\n",
      "Confusion Matrix:\n",
      "[[3585  317]\n",
      " [ 773 1086]]\n",
      "Accuracy: 0.8107967366776602\n",
      "Precision: 0.7740555951532431\n",
      "Recall: 0.5841850457235073\n",
      "\n",
      "PDC Value: 8\n",
      "Confusion Matrix:\n",
      "[[1357   93]\n",
      " [ 210  254]]\n",
      "Accuracy: 0.841692789968652\n",
      "Precision: 0.7319884726224783\n",
      "Recall: 0.5474137931034483\n",
      "\n",
      "PDC Value: 4\n",
      "Confusion Matrix:\n",
      "[[243  35]\n",
      " [ 46 130]]\n",
      "Accuracy: 0.8215859030837004\n",
      "Precision: 0.7878787878787878\n",
      "Recall: 0.7386363636363636\n",
      "Confusion matrix results for each 'pdc' value on df_70:\n",
      "   pdc_value                  conf_matrix  accuracy  precision    recall\n",
      "0          1   [[4418, 356], [811, 1179]]  0.827469   0.768078  0.592462\n",
      "1          0   [[3754, 480], [909, 1575]]  0.793242   0.766423  0.634058\n",
      "2          3   [[4232, 472], [908, 1516]]  0.806397   0.762575  0.625413\n",
      "3          6  [[6857, 483], [1153, 1481]]  0.835974   0.754073  0.562263\n",
      "4          5    [[1878, 167], [387, 418]]  0.805614   0.714530  0.519255\n",
      "5          2   [[3809, 364], [748, 1183]]  0.817824   0.764706  0.612636\n",
      "6          9    [[2327, 211], [496, 568]]  0.803720   0.729140  0.533835\n",
      "7          7   [[3585, 317], [773, 1086]]  0.810797   0.774056  0.584185\n",
      "8          8     [[1357, 93], [210, 254]]  0.841693   0.731988  0.547414\n",
      "9          4       [[243, 35], [46, 130]]  0.821586   0.787879  0.738636\n",
      "Evaluation on df_30 (30% hold-out data):\n",
      "Accuracy: 0.8204284485465791\n",
      "Precision: 0.7563525972565774\n",
      "Recall: 0.6040768678160919\n",
      "Confusion Matrix:\n",
      "[[46635  4334]\n",
      " [ 8818 13454]]\n",
      "\n",
      "PDC Value: 9\n",
      "Confusion Matrix:\n",
      "[[3262  291]\n",
      " [ 668  870]]\n",
      "Accuracy: 0.8116283637792182\n",
      "Precision: 0.7493540051679587\n",
      "Recall: 0.5656697009102731\n",
      "\n",
      "PDC Value: 2\n",
      "Confusion Matrix:\n",
      "[[5516  519]\n",
      " [1001 1705]]\n",
      "Accuracy: 0.8261068527628418\n",
      "Precision: 0.766636690647482\n",
      "Recall: 0.6300813008130082\n",
      "\n",
      "PDC Value: 1\n",
      "Confusion Matrix:\n",
      "[[6308  550]\n",
      " [1129 1677]]\n",
      "Accuracy: 0.8262624172185431\n",
      "Precision: 0.7530309833857207\n",
      "Recall: 0.597647897362794\n",
      "\n",
      "PDC Value: 3\n",
      "Confusion Matrix:\n",
      "[[6135  691]\n",
      " [1249 2266]]\n",
      "Accuracy: 0.8123972536505174\n",
      "Precision: 0.7663172133919514\n",
      "Recall: 0.6446657183499289\n",
      "\n",
      "PDC Value: 6\n",
      "Confusion Matrix:\n",
      "[[9676  680]\n",
      " [1516 2072]]\n",
      "Accuracy: 0.842512908777969\n",
      "Precision: 0.752906976744186\n",
      "Recall: 0.5774804905239688\n",
      "\n",
      "PDC Value: 8\n",
      "Confusion Matrix:\n",
      "[[2117  137]\n",
      " [ 300  402]]\n",
      "Accuracy: 0.8521650879566982\n",
      "Precision: 0.7458256029684601\n",
      "Recall: 0.5726495726495726\n",
      "\n",
      "PDC Value: 0\n",
      "Confusion Matrix:\n",
      "[[5457  707]\n",
      " [1229 2171]]\n",
      "Accuracy: 0.7975742367210372\n",
      "Precision: 0.7543432939541348\n",
      "Recall: 0.6385294117647059\n",
      "\n",
      "PDC Value: 7\n",
      "Confusion Matrix:\n",
      "[[5201  466]\n",
      " [1092 1531]]\n",
      "Accuracy: 0.8120627261761159\n",
      "Precision: 0.7666499749624437\n",
      "Recall: 0.5836828059473885\n",
      "\n",
      "PDC Value: 5\n",
      "Confusion Matrix:\n",
      "[[2619  243]\n",
      " [ 568  575]]\n",
      "Accuracy: 0.7975031210986268\n",
      "Precision: 0.7029339853300733\n",
      "Recall: 0.5030621172353456\n",
      "\n",
      "PDC Value: 4\n",
      "Confusion Matrix:\n",
      "[[344  50]\n",
      " [ 66 185]]\n",
      "Accuracy: 0.8201550387596899\n",
      "Precision: 0.7872340425531915\n",
      "Recall: 0.7370517928286853\n",
      "Confusion matrix results for each 'pdc' value on df_30:\n",
      "   pdc_value                  conf_matrix  accuracy  precision    recall\n",
      "0          9    [[3262, 291], [668, 870]]  0.811628   0.749354  0.565670\n",
      "1          2  [[5516, 519], [1001, 1705]]  0.826107   0.766637  0.630081\n",
      "2          1  [[6308, 550], [1129, 1677]]  0.826262   0.753031  0.597648\n",
      "3          3  [[6135, 691], [1249, 2266]]  0.812397   0.766317  0.644666\n",
      "4          6  [[9676, 680], [1516, 2072]]  0.842513   0.752907  0.577480\n",
      "5          8    [[2117, 137], [300, 402]]  0.852165   0.745826  0.572650\n",
      "6          0  [[5457, 707], [1229, 2171]]  0.797574   0.754343  0.638529\n",
      "7          7  [[5201, 466], [1092, 1531]]  0.812063   0.766650  0.583683\n",
      "8          5    [[2619, 243], [568, 575]]  0.797503   0.702934  0.503062\n",
      "9          4       [[344, 50], [66, 185]]  0.820155   0.787234  0.737052\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, confusion_matrix\n",
    "\n",
    "# Splitting the data into 70% and 30% for training/initial testing and hold-out\n",
    "df_30, df_70 = train_test_split(data, test_size=0.7, random_state=42)\n",
    "\n",
    "# Prepare the training/initial testing dataset\n",
    "X_70 = df_70.drop(['rhit_label', 'rhit_within_2wks'], axis=1)\n",
    "y_70 = df_70['rhit_label']\n",
    "\n",
    "# Splitting df_70 into training and testing sets\n",
    "X_train_70, X_test_70, y_train_70, y_test_70 = train_test_split(X_70, y_70, \n",
    "                                                                test_size=0.3, \n",
    "                                                                stratify=y_70, \n",
    "                                                                random_state=42)\n",
    "\n",
    "# Initialize the XGBoost classifier\n",
    "xgb_classifier = XGBClassifier(objective='binary:logistic', \n",
    "                               max_depth=10, \n",
    "                               min_child_weight=180, \n",
    "                               random_state=100, \n",
    "                               use_label_encoder=False, \n",
    "                               eval_metric='logloss')\n",
    "\n",
    "# Train the XGBoost model\n",
    "xgb_classifier.fit(X_train_70, y_train_70)\n",
    "\n",
    "# Predicting the test set results for df_70\n",
    "y_pred_70 = xgb_classifier.predict(X_test_70)\n",
    "\n",
    "# Evaluating the model on df_70\n",
    "accuracy_70 = accuracy_score(y_test_70, y_pred_70)\n",
    "precision_70 = precision_score(y_test_70, y_pred_70, average='binary')\n",
    "recall_70 = recall_score(y_test_70, y_pred_70, average='binary')\n",
    "\n",
    "# Printing the evaluation metrics for df_70\n",
    "print(\"Evaluation on df_70 (70% data):\")\n",
    "print(f\"Accuracy: {accuracy_70}\")\n",
    "print(f\"Precision: {precision_70}\")\n",
    "print(f\"Recall: {recall_70}\")\n",
    "\n",
    "# Confusion matrix for df_70\n",
    "conf_matrix_70 = confusion_matrix(y_test_70, y_pred_70)\n",
    "print(f\"Confusion Matrix:\\n{conf_matrix_70}\")\n",
    "\n",
    "# Confusion matrix for each unique value in 'pdc' in the test set of df_70\n",
    "unique_pdc_values = X_test_70['pdc'].unique()\n",
    "confResults = []\n",
    "\n",
    "for pdc_value in unique_pdc_values:\n",
    "    # Selecting the subset of data where 'pdc' equals the current value\n",
    "    subset_index = X_test_70[X_test_70['pdc'] == pdc_value].index\n",
    "    y_test_subset = y_test_70.loc[subset_index]\n",
    "    \n",
    "    # Predicting the subset of test data\n",
    "    y_pred_subset = xgb_classifier.predict(X_test_70.loc[subset_index])\n",
    "    \n",
    "    # Calculating confusion matrix\n",
    "    conf_matrix = confusion_matrix(y_test_subset, y_pred_subset)\n",
    "    accuracy = accuracy_score(y_test_subset, y_pred_subset)\n",
    "    precision = precision_score(y_test_subset, y_pred_subset, average='binary')\n",
    "    recall = recall_score(y_test_subset, y_pred_subset, average='binary')\n",
    "    \n",
    "    print(f\"\\nPDC Value: {pdc_value}\")\n",
    "    print(f\"Confusion Matrix:\\n{conf_matrix}\")\n",
    "    print(f\"Accuracy: {accuracy}\")\n",
    "    print(f\"Precision: {precision}\")\n",
    "    print(f\"Recall: {recall}\")\n",
    "    \n",
    "    confResults.append({\n",
    "        'pdc_value': pdc_value,\n",
    "        'conf_matrix': conf_matrix,\n",
    "        'accuracy': accuracy,\n",
    "        'precision': precision,\n",
    "        'recall': recall\n",
    "    })\n",
    "    \n",
    "confResults_df_70 = pd.DataFrame(confResults)\n",
    "\n",
    "# Optionally, display the DataFrame\n",
    "print(\"Confusion matrix results for each 'pdc' value on df_70:\")\n",
    "print(confResults_df_70)\n",
    "\n",
    "# Evaluate the model on df_30 as hold-out data\n",
    "X_30 = df_30.drop(['rhit_label', 'rhit_within_2wks'], axis=1)\n",
    "y_30 = df_30['rhit_label']\n",
    "\n",
    "# Predicting the hold-out set results for df_30\n",
    "y_pred_30 = xgb_classifier.predict(X_30)\n",
    "\n",
    "# Evaluating the model on df_30\n",
    "accuracy_30 = accuracy_score(y_30, y_pred_30)\n",
    "precision_30 = precision_score(y_30, y_pred_30, average='binary')\n",
    "recall_30 = recall_score(y_30, y_pred_30, average='binary')\n",
    "\n",
    "# Printing the evaluation metrics for df_30\n",
    "print(\"Evaluation on df_30 (30% hold-out data):\")\n",
    "print(f\"Accuracy: {accuracy_30}\")\n",
    "print(f\"Precision: {precision_30}\")\n",
    "print(f\"Recall: {recall_30}\")\n",
    "\n",
    "# Confusion matrix for df_30\n",
    "conf_matrix_30 = confusion_matrix(y_30, y_pred_30)\n",
    "print(f\"Confusion Matrix:\\n{conf_matrix_30}\")\n",
    "\n",
    "# Confusion matrix for each unique value in 'pdc' in df_30\n",
    "unique_pdc_values_30 = X_30['pdc'].unique()\n",
    "confResults_30 = []\n",
    "\n",
    "for pdc_value in unique_pdc_values_30:\n",
    "    # Selecting the subset of data where 'pdc' equals the current value\n",
    "    subset_index = X_30[X_30['pdc'] == pdc_value].index\n",
    "    y_test_subset_30 = y_30.loc[subset_index]\n",
    "    \n",
    "    # Predicting the subset of hold-out data\n",
    "    y_pred_subset_30 = xgb_classifier.predict(X_30.loc[subset_index])\n",
    "    \n",
    "    # Calculating confusion matrix\n",
    "    conf_matrix_30 = confusion_matrix(y_test_subset_30, y_pred_subset_30)\n",
    "    accuracy_30 = accuracy_score(y_test_subset_30, y_pred_subset_30)\n",
    "    precision_30 = precision_score(y_test_subset_30, y_pred_subset_30, average='binary')\n",
    "    recall_30 = recall_score(y_test_subset_30, y_pred_subset_30, average='binary')\n",
    "    \n",
    "    print(f\"\\nPDC Value: {pdc_value}\")\n",
    "    print(f\"Confusion Matrix:\\n{conf_matrix_30}\")\n",
    "    print(f\"Accuracy: {accuracy_30}\")\n",
    "    print(f\"Precision: {precision_30}\")\n",
    "    print(f\"Recall: {recall_30}\")\n",
    "    \n",
    "    confResults_30.append({\n",
    "        'pdc_value': pdc_value,\n",
    "        'conf_matrix': conf_matrix_30,\n",
    "        'accuracy': accuracy_30,\n",
    "        'precision': precision_30,\n",
    "        'recall': recall_30\n",
    "    })\n",
    "    \n",
    "confResults_df_30 = pd.DataFrame(confResults_30)\n",
    "\n",
    "# Optionally, display the DataFrame\n",
    "print(\"Confusion matrix results for each 'pdc' value on df_30:\")\n",
    "print(confResults_df_30)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "9c2668d2-21d0-4ef0-81f2-144fb5dff333",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation on df_70 (70% data):\n",
      "Accuracy: 0.8162827439583374\n",
      "Precision: 0.7592173350582148\n",
      "Recall: 0.5931400416903544\n",
      "Confusion Matrix:\n",
      "[[32460  2978]\n",
      " [ 6441  9390]]\n",
      "\n",
      "Desk Value: 2\n",
      "Confusion Matrix:\n",
      "[[1721  116]\n",
      " [ 302  230]]\n",
      "Accuracy: 0.8235542422963276\n",
      "Precision: 0.6647398843930635\n",
      "Recall: 0.4323308270676692\n",
      "\n",
      "Desk Value: 1\n",
      "Confusion Matrix:\n",
      "[[2560  144]\n",
      " [ 441  366]]\n",
      "Accuracy: 0.8333808031899743\n",
      "Precision: 0.7176470588235294\n",
      "Recall: 0.45353159851301117\n",
      "\n",
      "Desk Value: 3\n",
      "Confusion Matrix:\n",
      "[[1574  116]\n",
      " [ 265  925]]\n",
      "Accuracy: 0.8677083333333333\n",
      "Precision: 0.8885686839577329\n",
      "Recall: 0.7773109243697479\n",
      "\n",
      "Desk Value: 9\n",
      "Confusion Matrix:\n",
      "[[3330  302]\n",
      " [ 596 1149]]\n",
      "Accuracy: 0.8329923749302585\n",
      "Precision: 0.791867677463818\n",
      "Recall: 0.6584527220630373\n",
      "\n",
      "Desk Value: 15\n",
      "Confusion Matrix:\n",
      "[[3472  552]\n",
      " [ 957 1608]]\n",
      "Accuracy: 0.7709819395962969\n",
      "Precision: 0.7444444444444445\n",
      "Recall: 0.6269005847953216\n",
      "\n",
      "Desk Value: 7\n",
      "Confusion Matrix:\n",
      "[[1051  121]\n",
      " [ 257  310]]\n",
      "Accuracy: 0.7826336975273146\n",
      "Precision: 0.7192575406032483\n",
      "Recall: 0.54673721340388\n",
      "\n",
      "Desk Value: 0\n",
      "Confusion Matrix:\n",
      "[[1716  220]\n",
      " [ 381  806]]\n",
      "Accuracy: 0.8075568363752802\n",
      "Precision: 0.7855750487329435\n",
      "Recall: 0.6790227464195451\n",
      "\n",
      "Desk Value: 14\n",
      "Confusion Matrix:\n",
      "[[1515  105]\n",
      " [ 222  314]]\n",
      "Accuracy: 0.8483302411873841\n",
      "Precision: 0.7494033412887828\n",
      "Recall: 0.585820895522388\n",
      "\n",
      "Desk Value: 10\n",
      "Confusion Matrix:\n",
      "[[2909  199]\n",
      " [ 566  556]]\n",
      "Accuracy: 0.8191489361702128\n",
      "Precision: 0.7364238410596027\n",
      "Recall: 0.49554367201426025\n",
      "\n",
      "Desk Value: 8\n",
      "Confusion Matrix:\n",
      "[[2217  178]\n",
      " [ 426  391]]\n",
      "Accuracy: 0.8119551681195517\n",
      "Precision: 0.687170474516696\n",
      "Recall: 0.4785801713586291\n",
      "\n",
      "Desk Value: 12\n",
      "Confusion Matrix:\n",
      "[[1817  302]\n",
      " [ 511  973]]\n",
      "Accuracy: 0.7743547044129891\n",
      "Precision: 0.7631372549019608\n",
      "Recall: 0.6556603773584906\n",
      "\n",
      "Desk Value: 16\n",
      "Confusion Matrix:\n",
      "[[1311  152]\n",
      " [ 283  495]]\n",
      "Accuracy: 0.8058902275769746\n",
      "Precision: 0.7650695517774343\n",
      "Recall: 0.6362467866323908\n",
      "\n",
      "Desk Value: 11\n",
      "Confusion Matrix:\n",
      "[[2295   80]\n",
      " [ 267  261]]\n",
      "Accuracy: 0.8804684808818464\n",
      "Precision: 0.7653958944281525\n",
      "Recall: 0.4943181818181818\n",
      "\n",
      "Desk Value: 4\n",
      "Confusion Matrix:\n",
      "[[1382  109]\n",
      " [ 313  302]]\n",
      "Accuracy: 0.7996201329534662\n",
      "Precision: 0.7347931873479319\n",
      "Recall: 0.49105691056910566\n",
      "\n",
      "Desk Value: 13\n",
      "Confusion Matrix:\n",
      "[[934  30]\n",
      " [ 90  45]]\n",
      "Accuracy: 0.8908098271155596\n",
      "Precision: 0.6\n",
      "Recall: 0.3333333333333333\n",
      "\n",
      "Desk Value: 6\n",
      "Confusion Matrix:\n",
      "[[1554  145]\n",
      " [ 296  399]]\n",
      "Accuracy: 0.8157894736842105\n",
      "Precision: 0.7334558823529411\n",
      "Recall: 0.5741007194244604\n",
      "\n",
      "Desk Value: 5\n",
      "Confusion Matrix:\n",
      "[[1102  107]\n",
      " [ 268  260]]\n",
      "Accuracy: 0.7841105354058722\n",
      "Precision: 0.7084468664850136\n",
      "Recall: 0.49242424242424243\n",
      "Confusion matrix results for each 'Desk' value on df_70:\n",
      "    Desk_value                 conf_matrix  accuracy  precision    recall\n",
      "0            2   [[1721, 116], [302, 230]]  0.823554   0.664740  0.432331\n",
      "1            1   [[2560, 144], [441, 366]]  0.833381   0.717647  0.453532\n",
      "2            3   [[1574, 116], [265, 925]]  0.867708   0.888569  0.777311\n",
      "3            9  [[3330, 302], [596, 1149]]  0.832992   0.791868  0.658453\n",
      "4           15  [[3472, 552], [957, 1608]]  0.770982   0.744444  0.626901\n",
      "5            7   [[1051, 121], [257, 310]]  0.782634   0.719258  0.546737\n",
      "6            0   [[1716, 220], [381, 806]]  0.807557   0.785575  0.679023\n",
      "7           14   [[1515, 105], [222, 314]]  0.848330   0.749403  0.585821\n",
      "8           10   [[2909, 199], [566, 556]]  0.819149   0.736424  0.495544\n",
      "9            8   [[2217, 178], [426, 391]]  0.811955   0.687170  0.478580\n",
      "10          12   [[1817, 302], [511, 973]]  0.774355   0.763137  0.655660\n",
      "11          16   [[1311, 152], [283, 495]]  0.805890   0.765070  0.636247\n",
      "12          11    [[2295, 80], [267, 261]]  0.880468   0.765396  0.494318\n",
      "13           4   [[1382, 109], [313, 302]]  0.799620   0.734793  0.491057\n",
      "14          13       [[934, 30], [90, 45]]  0.890810   0.600000  0.333333\n",
      "15           6   [[1554, 145], [296, 399]]  0.815789   0.733456  0.574101\n",
      "16           5   [[1102, 107], [268, 260]]  0.784111   0.708447  0.492424\n",
      "Evaluation on df_30 (30% hold-out data):\n",
      "Accuracy: 0.8204284485465791\n",
      "Precision: 0.7563525972565774\n",
      "Recall: 0.6040768678160919\n",
      "Confusion Matrix:\n",
      "[[46635  4334]\n",
      " [ 8818 13454]]\n",
      "\n",
      "Desk Value: 16\n",
      "Confusion Matrix:\n",
      "[[1893  215]\n",
      " [ 393  709]]\n",
      "Accuracy: 0.8105919003115265\n",
      "Precision: 0.7673160173160173\n",
      "Recall: 0.6433756805807622\n",
      "\n",
      "Desk Value: 15\n",
      "Confusion Matrix:\n",
      "[[4847  803]\n",
      " [1317 2265]]\n",
      "Accuracy: 0.770363951473137\n",
      "Precision: 0.7382659713168188\n",
      "Recall: 0.6323283082077052\n",
      "\n",
      "Desk Value: 13\n",
      "Confusion Matrix:\n",
      "[[1343   30]\n",
      " [ 112   69]]\n",
      "Accuracy: 0.9086229086229086\n",
      "Precision: 0.696969696969697\n",
      "Recall: 0.3812154696132597\n",
      "\n",
      "Desk Value: 3\n",
      "Confusion Matrix:\n",
      "[[2329  181]\n",
      " [ 312 1433]]\n",
      "Accuracy: 0.8841363102232668\n",
      "Precision: 0.8878562577447335\n",
      "Recall: 0.8212034383954154\n",
      "\n",
      "Desk Value: 10\n",
      "Confusion Matrix:\n",
      "[[4330  278]\n",
      " [ 718  776]]\n",
      "Accuracy: 0.8367748279252704\n",
      "Precision: 0.7362428842504743\n",
      "Recall: 0.5194109772423026\n",
      "\n",
      "Desk Value: 4\n",
      "Confusion Matrix:\n",
      "[[2015  169]\n",
      " [ 462  426]]\n",
      "Accuracy: 0.7945963541666666\n",
      "Precision: 0.7159663865546219\n",
      "Recall: 0.4797297297297297\n",
      "\n",
      "Desk Value: 0\n",
      "Confusion Matrix:\n",
      "[[2412  314]\n",
      " [ 521 1152]]\n",
      "Accuracy: 0.8101841327574448\n",
      "Precision: 0.7858117326057299\n",
      "Recall: 0.6885833831440527\n",
      "\n",
      "Desk Value: 11\n",
      "Confusion Matrix:\n",
      "[[3378  119]\n",
      " [ 368  386]]\n",
      "Accuracy: 0.8854387203011056\n",
      "Precision: 0.7643564356435644\n",
      "Recall: 0.5119363395225465\n",
      "\n",
      "Desk Value: 12\n",
      "Confusion Matrix:\n",
      "[[2630  491]\n",
      " [ 640 1373]]\n",
      "Accuracy: 0.779703934553954\n",
      "Precision: 0.7365879828326181\n",
      "Recall: 0.682066567312469\n",
      "\n",
      "Desk Value: 1\n",
      "Confusion Matrix:\n",
      "[[3591  211]\n",
      " [ 584  451]]\n",
      "Accuracy: 0.835641926814141\n",
      "Precision: 0.6812688821752266\n",
      "Recall: 0.4357487922705314\n",
      "\n",
      "Desk Value: 8\n",
      "Confusion Matrix:\n",
      "[[3149  227]\n",
      " [ 579  560]]\n",
      "Accuracy: 0.821483942414175\n",
      "Precision: 0.7115628970775095\n",
      "Recall: 0.4916593503072871\n",
      "\n",
      "Desk Value: 2\n",
      "Confusion Matrix:\n",
      "[[2367  172]\n",
      " [ 429  338]]\n",
      "Accuracy: 0.8182093163944344\n",
      "Precision: 0.6627450980392157\n",
      "Recall: 0.4406779661016949\n",
      "\n",
      "Desk Value: 9\n",
      "Confusion Matrix:\n",
      "[[4898  431]\n",
      " [ 880 1568]]\n",
      "Accuracy: 0.8314259997428314\n",
      "Precision: 0.784392196098049\n",
      "Recall: 0.6405228758169934\n",
      "\n",
      "Desk Value: 7\n",
      "Confusion Matrix:\n",
      "[[1396  176]\n",
      " [ 328  524]]\n",
      "Accuracy: 0.7920792079207921\n",
      "Precision: 0.7485714285714286\n",
      "Recall: 0.6150234741784038\n",
      "\n",
      "Desk Value: 5\n",
      "Confusion Matrix:\n",
      "[[1607  123]\n",
      " [ 355  360]]\n",
      "Accuracy: 0.8044989775051125\n",
      "Precision: 0.7453416149068323\n",
      "Recall: 0.5034965034965035\n",
      "\n",
      "Desk Value: 6\n",
      "Confusion Matrix:\n",
      "[[2210  230]\n",
      " [ 457  604]]\n",
      "Accuracy: 0.803770351328192\n",
      "Precision: 0.7242206235011991\n",
      "Recall: 0.5692742695570217\n",
      "\n",
      "Desk Value: 14\n",
      "Confusion Matrix:\n",
      "[[2240  164]\n",
      " [ 363  460]]\n",
      "Accuracy: 0.8366904245429191\n",
      "Precision: 0.7371794871794872\n",
      "Recall: 0.5589307411907655\n",
      "Confusion matrix results for each 'Desk' value on df_30:\n",
      "    Desk_value                  conf_matrix  accuracy  precision    recall\n",
      "0           16    [[1893, 215], [393, 709]]  0.810592   0.767316  0.643376\n",
      "1           15  [[4847, 803], [1317, 2265]]  0.770364   0.738266  0.632328\n",
      "2           13      [[1343, 30], [112, 69]]  0.908623   0.696970  0.381215\n",
      "3            3   [[2329, 181], [312, 1433]]  0.884136   0.887856  0.821203\n",
      "4           10    [[4330, 278], [718, 776]]  0.836775   0.736243  0.519411\n",
      "5            4    [[2015, 169], [462, 426]]  0.794596   0.715966  0.479730\n",
      "6            0   [[2412, 314], [521, 1152]]  0.810184   0.785812  0.688583\n",
      "7           11    [[3378, 119], [368, 386]]  0.885439   0.764356  0.511936\n",
      "8           12   [[2630, 491], [640, 1373]]  0.779704   0.736588  0.682067\n",
      "9            1    [[3591, 211], [584, 451]]  0.835642   0.681269  0.435749\n",
      "10           8    [[3149, 227], [579, 560]]  0.821484   0.711563  0.491659\n",
      "11           2    [[2367, 172], [429, 338]]  0.818209   0.662745  0.440678\n",
      "12           9   [[4898, 431], [880, 1568]]  0.831426   0.784392  0.640523\n",
      "13           7    [[1396, 176], [328, 524]]  0.792079   0.748571  0.615023\n",
      "14           5    [[1607, 123], [355, 360]]  0.804499   0.745342  0.503497\n",
      "15           6    [[2210, 230], [457, 604]]  0.803770   0.724221  0.569274\n",
      "16          14    [[2240, 164], [363, 460]]  0.836690   0.737179  0.558931\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, confusion_matrix\n",
    "\n",
    "# Splitting the data into 70% and 30% for training/initial testing and hold-out\n",
    "df_30, df_70 = train_test_split(data, test_size=0.7, random_state=42)\n",
    "\n",
    "# Prepare the training/initial testing dataset\n",
    "X_70 = df_70.drop(['rhit_label', 'rhit_within_2wks'], axis=1)\n",
    "y_70 = df_70['rhit_label']\n",
    "\n",
    "# Splitting df_70 into training and testing sets\n",
    "X_train_70, X_test_70, y_train_70, y_test_70 = train_test_split(X_70, y_70, \n",
    "                                                                test_size=0.3, \n",
    "                                                                stratify=y_70, \n",
    "                                                                random_state=42)\n",
    "\n",
    "# Initialize the XGBoost classifier\n",
    "xgb_classifier = XGBClassifier(objective='binary:logistic', \n",
    "                               max_depth=10, \n",
    "                               min_child_weight=180, \n",
    "                               random_state=100, \n",
    "                               use_label_encoder=False, \n",
    "                               eval_metric='logloss')\n",
    "\n",
    "# Train the XGBoost model\n",
    "xgb_classifier.fit(X_train_70, y_train_70)\n",
    "\n",
    "# Predicting the test set results for df_70\n",
    "y_pred_70 = xgb_classifier.predict(X_test_70)\n",
    "\n",
    "# Evaluating the model on df_70\n",
    "accuracy_70 = accuracy_score(y_test_70, y_pred_70)\n",
    "precision_70 = precision_score(y_test_70, y_pred_70, average='binary')\n",
    "recall_70 = recall_score(y_test_70, y_pred_70, average='binary')\n",
    "\n",
    "# Printing the evaluation metrics for df_70\n",
    "print(\"Evaluation on df_70 (70% data):\")\n",
    "print(f\"Accuracy: {accuracy_70}\")\n",
    "print(f\"Precision: {precision_70}\")\n",
    "print(f\"Recall: {recall_70}\")\n",
    "\n",
    "# Confusion matrix for df_70\n",
    "conf_matrix_70 = confusion_matrix(y_test_70, y_pred_70)\n",
    "print(f\"Confusion Matrix:\\n{conf_matrix_70}\")\n",
    "\n",
    "# Confusion matrix for each unique value in 'Desk' in the test set of df_70\n",
    "unique_Desk_values = X_test_70['desk'].unique()\n",
    "confResults = []\n",
    "\n",
    "for Desk_value in unique_Desk_values:\n",
    "    # Selecting the subset of data where 'Desk' equals the current value\n",
    "    subset_index = X_test_70[X_test_70['desk'] == Desk_value].index\n",
    "    y_test_subset = y_test_70.loc[subset_index]\n",
    "    \n",
    "    # Predicting the subset of test data\n",
    "    y_pred_subset = xgb_classifier.predict(X_test_70.loc[subset_index])\n",
    "    \n",
    "    # Calculating confusion matrix\n",
    "    conf_matrix = confusion_matrix(y_test_subset, y_pred_subset)\n",
    "    accuracy = accuracy_score(y_test_subset, y_pred_subset)\n",
    "    precision = precision_score(y_test_subset, y_pred_subset, average='binary')\n",
    "    recall = recall_score(y_test_subset, y_pred_subset, average='binary')\n",
    "    \n",
    "    print(f\"\\nDesk Value: {Desk_value}\")\n",
    "    print(f\"Confusion Matrix:\\n{conf_matrix}\")\n",
    "    print(f\"Accuracy: {accuracy}\")\n",
    "    print(f\"Precision: {precision}\")\n",
    "    print(f\"Recall: {recall}\")\n",
    "    \n",
    "    confResults.append({\n",
    "        'Desk_value': Desk_value,\n",
    "        'conf_matrix': conf_matrix,\n",
    "        'accuracy': accuracy,\n",
    "        'precision': precision,\n",
    "        'recall': recall\n",
    "    })\n",
    "    \n",
    "confResults_df_70 = pd.DataFrame(confResults)\n",
    "\n",
    "# Optionally, display the DataFrame\n",
    "print(\"Confusion matrix results for each 'Desk' value on df_70:\")\n",
    "print(confResults_df_70)\n",
    "\n",
    "# Evaluate the model on df_30 as hold-out data\n",
    "X_30 = df_30.drop(['rhit_label', 'rhit_within_2wks'], axis=1)\n",
    "y_30 = df_30['rhit_label']\n",
    "\n",
    "# Predicting the hold-out set results for df_30\n",
    "y_pred_30 = xgb_classifier.predict(X_30)\n",
    "\n",
    "# Evaluating the model on df_30\n",
    "accuracy_30 = accuracy_score(y_30, y_pred_30)\n",
    "precision_30 = precision_score(y_30, y_pred_30, average='binary')\n",
    "recall_30 = recall_score(y_30, y_pred_30, average='binary')\n",
    "\n",
    "# Printing the evaluation metrics for df_30\n",
    "print(\"Evaluation on df_30 (30% hold-out data):\")\n",
    "print(f\"Accuracy: {accuracy_30}\")\n",
    "print(f\"Precision: {precision_30}\")\n",
    "print(f\"Recall: {recall_30}\")\n",
    "\n",
    "# Confusion matrix for df_30\n",
    "conf_matrix_30 = confusion_matrix(y_30, y_pred_30)\n",
    "print(f\"Confusion Matrix:\\n{conf_matrix_30}\")\n",
    "\n",
    "# Confusion matrix for each unique value in 'Desk' in df_30\n",
    "unique_Desk_values_30 = X_30['desk'].unique()\n",
    "confResults_30 = []\n",
    "\n",
    "for Desk_value in unique_Desk_values_30:\n",
    "    # Selecting the subset of data where 'Desk' equals the current value\n",
    "    subset_index = X_30[X_30['desk'] == Desk_value].index\n",
    "    y_test_subset_30 = y_30.loc[subset_index]\n",
    "    \n",
    "    # Predicting the subset of hold-out data\n",
    "    y_pred_subset_30 = xgb_classifier.predict(X_30.loc[subset_index])\n",
    "    \n",
    "    # Calculating confusion matrix\n",
    "    conf_matrix_30 = confusion_matrix(y_test_subset_30, y_pred_subset_30)\n",
    "    accuracy_30 = accuracy_score(y_test_subset_30, y_pred_subset_30)\n",
    "    precision_30 = precision_score(y_test_subset_30, y_pred_subset_30, average='binary')\n",
    "    recall_30 = recall_score(y_test_subset_30, y_pred_subset_30, average='binary')\n",
    "    \n",
    "    print(f\"\\nDesk Value: {Desk_value}\")\n",
    "    print(f\"Confusion Matrix:\\n{conf_matrix_30}\")\n",
    "    print(f\"Accuracy: {accuracy_30}\")\n",
    "    print(f\"Precision: {precision_30}\")\n",
    "    print(f\"Recall: {recall_30}\")\n",
    "    \n",
    "    confResults_30.append({\n",
    "        'Desk_value': Desk_value,\n",
    "        'conf_matrix': conf_matrix_30,\n",
    "        'accuracy': accuracy_30,\n",
    "        'precision': precision_30,\n",
    "        'recall': recall_30\n",
    "    })\n",
    "    \n",
    "confResults_df_30 = pd.DataFrame(confResults_30)\n",
    "\n",
    "# Optionally, display the DataFrame\n",
    "print(\"Confusion matrix results for each 'Desk' value on df_30:\")\n",
    "print(confResults_df_30)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "d1153b70-8e50-4a4b-8b76-7f1ccc3fe073",
   "metadata": {},
   "outputs": [],
   "source": [
    "desk15 = data[data['desk'].isin([3,4])].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "44d47237-bfb1-4403-a3bb-c9fbe19c69eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation on df_30 (30% hold-out data):\n",
      "Accuracy: 0.8546027272350478\n",
      "Precision: 0.8581025500411297\n",
      "Recall: 0.7167888227210261\n",
      "Confusion Matrix:\n",
      "[[14360  1035]\n",
      " [ 2473  6259]]\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model on df_30 as hold-out data\n",
    "X_30 = desk15.drop(['rhit_label', 'rhit_within_2wks'], axis=1)\n",
    "y_30 = desk15['rhit_label']\n",
    "\n",
    "# Predicting the hold-out set results for df_30\n",
    "y_pred_30 = xgb_classifier.predict(X_30)\n",
    "\n",
    "# Evaluating the model on df_30\n",
    "accuracy_30 = accuracy_score(y_30, y_pred_30)\n",
    "precision_30 = precision_score(y_30, y_pred_30, average='binary')\n",
    "recall_30 = recall_score(y_30, y_pred_30, average='binary')\n",
    "\n",
    "# Printing the evaluation metrics for df_30\n",
    "print(\"Evaluation on df_30 (30% hold-out data):\")\n",
    "print(f\"Accuracy: {accuracy_30}\")\n",
    "print(f\"Precision: {precision_30}\")\n",
    "print(f\"Recall: {recall_30}\")\n",
    "\n",
    "# Confusion matrix for df_30\n",
    "conf_matrix_30 = confusion_matrix(y_30, y_pred_30)\n",
    "print(f\"Confusion Matrix:\\n{conf_matrix_30}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49cfe189-96d0-477f-bf38-e78a91b90677",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "# Note: "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b151501-3ac8-4514-9ec1-6b2e380e9961",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "Other approached tried include:\n",
    "1. Using KNN classifier to fill in the missing values (found to be compute intensive, so had to drop it)\n",
    "2. Decision Tree analysis - to understand the relationships, and if all PDC's and Desk's, which we view as key entities in this analysis, have similar results.\n",
    "3. Since we observed that some Desk's and PDC's performed poorly when we used a simple decision tree analysis, we tried the following:\n",
    "    * And there was low recall for some categories, so we tried assigning class weights to penalise this behaviour, but that did not result in desired results in train case itself. So, had to leave this approach\n",
    "4. Next approach was to use clustering to identify different types of subsets and apply different models to them to improve accuracy and precision numbers. We have applied selectively Decision Tree and Random Forest algorithms to try and maximise the metrics, but that did not yield any better results.\n",
    "5. Finally, we tried Xgboost algorithm to predict values, which resulted in better results. But, we wanted to be sure of the results, so we performed a hold-out analysis separately to see if the results fluctuated or remained the same. We tried different usecases such as single desk, multiple desks, single PDC, multiple PDC's and also tried various skewed subsets and found metrics to be robust enough."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
